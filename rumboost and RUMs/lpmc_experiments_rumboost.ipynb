{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## Import packages\n",
    "import pandas as pd  # For file input/output\n",
    "from scipy import optimize\n",
    "from scipy.optimize._numdiff import approx_derivative\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "import gc\n",
    "#import matplotlib.pyplot as plt\n",
    "#import shap\n",
    "from rumbooster import rum_train\n",
    "from utils import bio_to_rumboost\n",
    "from datasets import load_preprocess_LPMC\n",
    "from models import LPMC, LPMC_normalised, LPMC_nested_normalised, LPMC_cross_nested_normalised, LPMC_mixed_logit_tt\n",
    "from benchmarks import return_dataset, prepare_model, estimate_models, prepare_labels, predict_test, predict_proba\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "\n",
    "# Load common functions for the experiments\n",
    "from expermients_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize matplotlib\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    \"text.usetex\": True, \n",
    "    \"font.family\": \"serif\",\n",
    "    # Use 14pt font in plots, to match 10pt font in document\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"font.size\": 14,\n",
    "    # Make the legend/label fonts a little smaller\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12\n",
    "}\n",
    "\n",
    "#plt.rcParams.update(tex_fonts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment parameters\n",
    "data_dir = \"../Data/\"\n",
    "adjusted_hyperparms_dir = \"../Data/adjusted-hyperparameters/\"\n",
    "train_suffix = \"_train.csv\"\n",
    "test_suffix = \"_test.csv\"\n",
    "hyperparameters_suffix = \"_hyperparameters\"\n",
    "reset_crossval_indices = 0 # Set to 0 for reproducibility of the experiment over multiple executions\n",
    "partial_results_dir = \"../Data/Results-RealDatasets/\"\n",
    "\n",
    "recompute_Experiment_4 = True\n",
    "\n",
    "rounding = 2\n",
    "\n",
    "CV = 5 # Number of cross-validation\n",
    "n_iter = 100 #  Number of iterations used on the random search\n",
    "average_tech = \"macro\" #\"micro\"\n",
    "\n",
    "hyperparameters_suffix = hyperparameters_suffix +'_'+ str(n_iter) + '.csv'\n",
    "\n",
    "model_type_to_class = {\"RUMBoost\": \"RUMBoost\",\n",
    "                       \"Nested_RUMBoost\": \"Nested_RUMBoost\",\n",
    "                       'Cross-nested_RUMBoost': 'Cross-nested_RUMBoost',\n",
    "                       \"Full_Effect_RUMBoost\": \"Full_Effect_RUMBoost\",\n",
    "                       'RUMBoost_FI': 'RUMBoost_FI',\n",
    "                       \"MNL\":\"MNL\",\n",
    "                       \"Nested_MNL\": \"Nested_MNL\",\n",
    "                       \"CNL\": \"CNL\",\n",
    "                       #\"Mixed Logit\": \"Mixed Logit\"\n",
    "                       }\n",
    "\n",
    "STATIC_PARAMS = {'n_jobs': -1,\n",
    "                 'num_classes':4,\n",
    "                 'objective':'multiclass',\n",
    "                 'boosting': 'gbdt',\n",
    "                 'monotone_constraints_method': 'advanced',\n",
    "                 'verbosity': -1,\n",
    "                 'num_iterations':3000,\n",
    "                 'early_stopping_round':100,\n",
    "                 'learning_rate':0.1\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"LPMC\": {\n",
    "                  \"name\": \"LPMC\",\n",
    "                  \"mode_var\": \"travel_mode\",\n",
    "                  \"individual_id\": \"household_id\",\n",
    "                  \"alt_names\": [\"Walk\", \"Bike\", \"Public transport\", \"Car\"]\n",
    "                }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data\n",
    "def load_data(dataset_id, dataset):\n",
    "    train = pd.read_csv(data_dir + dataset_id + train_suffix, sep=',')\n",
    "    final_test = pd.read_csv(data_dir + dataset_id + test_suffix, sep=',')\n",
    "\n",
    "    train['distance'] = train['distance']/1000\n",
    "    final_test['distance'] = final_test['distance']/1000\n",
    "    # Divide the dataset into charasteristics and target variable\n",
    "    X = train.loc[:, train.columns != dataset[\"mode_var\"]]\n",
    "    y = train[dataset[\"mode_var\"]]\n",
    "    final_test_X = final_test.loc[:, final_test.columns != dataset[\"mode_var\"]]\n",
    "    final_test_y = final_test[dataset[\"mode_var\"]]\n",
    "\n",
    "    alts = list(y.unique()) # List containing al the modes (alternatives) in the dataset\n",
    "\n",
    "    # Extract the individual ID to later group observations using it\n",
    "    groups = np.array(X[dataset[\"individual_id\"]].values)\n",
    "    X = X.drop(columns=dataset[\"individual_id\"])\n",
    "    final_test_X = final_test_X.drop(columns=dataset[\"individual_id\"])\n",
    "\n",
    "    # Load the hyperparameters\n",
    "    try:\n",
    "        adjusted_hyperparameters_file = pd.read_csv(adjusted_hyperparms_dir + dataset_id + hyperparameters_suffix , index_col=0)\n",
    "        hyperparameters = adjusted_hyperparameters_file.to_dict()\n",
    "    except (OSError, IOError) as e:\n",
    "        print(\"Error while loading best_hyperparameters for dataset {} - {}...\".format(dataset_id, n_iter))\n",
    "        pass\n",
    "\n",
    "    return (X, y, final_test_X, final_test_y, alts, groups, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the classifier\n",
    "def create_classifier(classifier, hyperparameters, dataset, X, y, for_CV=False):\n",
    "    clf_hyperparameters = copy.deepcopy(hyperparameters)\n",
    "    integer_params = ['max_bin','min_data_in_leaf','num_leaves','num_iterations']\n",
    "    float_params = ['bagging_fraction','feature_fraction','lambda_l1','lambda_l2','min_gain_to_split','min_sum_hessian_in_leaf', 'mu']\n",
    "    choice_params = {\"learning_rate\": [0.05, 0.1], \n",
    "                    \"bagging_freq\": [0, 1, 5, 10],\n",
    "                    \"nest\": [{0:0, 1:1, 2:2, 3:2}, {0:0, 1:0, 2:1, 3:0}],\n",
    "                    \"max_depth\": [0]\n",
    "                    }\n",
    "\n",
    "    static_params = copy.deepcopy(STATIC_PARAMS)\n",
    "\n",
    "    for k in list(clf_hyperparameters[classifier].keys()):\n",
    "        if k == \"_best_iter\":\n",
    "            clf_hyperparameters[classifier]['num_iterations'] = int(clf_hyperparameters[classifier][k])\n",
    "            del clf_hyperparameters[classifier][k]\n",
    "            continue\n",
    "        if k.startswith('_'):\n",
    "            del clf_hyperparameters[classifier][k]\n",
    "            continue\n",
    "        if np.isnan(clf_hyperparameters[classifier][k]):\n",
    "            del clf_hyperparameters[classifier][k]\n",
    "            continue\n",
    "        if k in integer_params:\n",
    "            clf_hyperparameters[classifier][k] = int(clf_hyperparameters[classifier][k])\n",
    "        if k in float_params:\n",
    "            clf_hyperparameters[classifier][k] = clf_hyperparameters[classifier][k]\n",
    "        if k in choice_params.keys():\n",
    "            clf_hyperparameters[classifier][k] = choice_params[k][int(clf_hyperparameters[classifier][k])]\n",
    "\n",
    "    params = {**clf_hyperparameters[classifier], **static_params}\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4.1: Which is the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct Experiment 4 - Accuracy, GMPCA and Time Tables\n",
    "def construct_experiment_4_accuracy_table(Experiment_4_CV_scores, Experiment_4_test_scores):\n",
    "    columns = [\"Accuracy\", \"GMPCA\"]\n",
    "\n",
    "    # Compute the mean of all the stored results for all the models and construct the final table\n",
    "    train_scores_df = {}\n",
    "    test_scores_df = {}\n",
    "    time_scores_df = {}\n",
    "\n",
    "    Experiment_4_CV_scores_mean = copy.deepcopy(Experiment_4_CV_scores)\n",
    "    Experiment_4_test_scores_round = copy.deepcopy(Experiment_4_test_scores)\n",
    "    for k_clf in model_type_to_class.keys():\n",
    "        for k_dataset in Experiment_4_CV_scores_mean[k_clf].keys():\n",
    "            for k_score in Experiment_4_CV_scores_mean[k_clf][k_dataset].keys():\n",
    "                if k_score in columns + ['Estimation time']:\n",
    "                    Experiment_4_CV_scores_mean[k_clf][k_dataset][k_score] = np.round(np.mean(Experiment_4_CV_scores_mean[k_clf][k_dataset][k_score]), rounding)\n",
    "                    Experiment_4_test_scores_round[k_clf][k_dataset][k_score] = np.round(Experiment_4_test_scores_round[k_clf][k_dataset][k_score], rounding)\n",
    "        \n",
    "        train_scores_df[k_clf] = pd.DataFrame(Experiment_4_CV_scores_mean[k_clf]).T[columns]\n",
    "        test_scores_df[k_clf] = pd.DataFrame(Experiment_4_test_scores_round[k_clf]).T[columns]\n",
    "        time_scores_df[k_clf] = pd.DataFrame(Experiment_4_CV_scores_mean[k_clf]).T['Estimation time']\n",
    "        \n",
    "    Experiment_4_CV_table = pd.concat(train_scores_df, axis=1)\n",
    "    Experiment_4_test_table = pd.concat(test_scores_df, axis=1)\n",
    "    Experiment_4_time_table = pd.concat(time_scores_df, axis=1)\n",
    "\n",
    "    return (Experiment_4_CV_table, Experiment_4_test_table, Experiment_4_time_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "--- LPMC (ID: LPMC)\n",
      "\n",
      "\t--- Mixed Logit\n",
      "\t\t CV it: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2024-07-28 22:02:23,800 LPMC Mixed Logit <models.py:449>\n",
      "[INFO] 2024-07-28 22:02:23,805 Parameters read from biogeme.toml <toml.py:66>\n",
      "[INFO] 2024-07-28 22:02:58,958 *** Initial values of the parameters are obtained from the file __LPMC_mixed_logit.iter <biogeme.py:1271>\n",
      "[INFO] 2024-07-28 22:02:59,076 Parameter values restored from __LPMC_mixed_logit.iter <biogeme.py:1051>\n",
      "[DEBUG] 2024-07-28 22:03:07,619 Log likelihood (N = 43812):  -61705.77 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-28 22:03:07,619 Run simple_bounds <biogeme.py:1515>\n",
      "[INFO] 2024-07-28 22:03:07,619 Optimization algorithm: hybrid Newton/BFGS with simple bounds [simple_bounds] <optimization.py:437>\n",
      "[INFO] 2024-07-28 22:03:07,620 ** Optimization: Hybrid Newton 10.0%/BFGS with trust region for simple bounds <optimization.py:480>\n",
      "[DEBUG] 2024-07-29 02:50:33,918 Log likelihood (N = 43812):  -61705.77 Gradient norm:      6e+05 Hessian norm:       3e+07  <biogeme.py:935>\n",
      "[DEBUG] 2024-07-29 02:54:33,057 Log likelihood (N = 43812):  -42485.53 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 04:07:11,846 Log likelihood (N = 43812):  -42485.53 Gradient norm:      1e+05   <biogeme.py:935>\n",
      "[DEBUG] 2024-07-29 04:07:11,848 1 f= 0.9697236 projected rel. grad.=   1.7 rel. change=     1 delta= 1e+02 rho=  0.79 + <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 04:11:26,450 Log likelihood (N = 43812):  -416007.8 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 04:11:26,451 2 f= 0.9697236 projected rel. grad.=   1.7 rel. change=     1 delta=    50 rho= -0.11 - <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 04:15:42,560 Log likelihood (N = 43812):  -225019.4 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 04:15:42,560 3 f= 0.9697236 projected rel. grad.=   1.7 rel. change=     1 delta=    25 rho= -0.19 - <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 04:19:57,429 Log likelihood (N = 43812):  -123371.6 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 04:19:57,430 4 f= 0.9697236 projected rel. grad.=   1.7 rel. change=     1 delta=    12 rho= -0.27 - <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 04:24:13,378 Log likelihood (N = 43812):  -71500.66 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 04:24:13,378 5 f= 0.9697236 projected rel. grad.=   1.7 rel. change=     1 delta=   6.2 rho= -0.28 - <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 04:28:27,406 Log likelihood (N = 43812):  -47141.02 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 04:28:27,407 6 f= 0.9697236 projected rel. grad.=   1.7 rel. change=     1 delta=   3.1 rho= -0.11 - <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 04:32:44,145 Log likelihood (N = 43812):  -37424.58 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 05:48:06,217 Log likelihood (N = 43812):  -37424.58 Gradient norm:      2e+05   <biogeme.py:935>\n",
      "[DEBUG] 2024-07-29 05:48:06,219 7 f= 0.8542085 projected rel. grad.=   2.7 rel. change=   1.2 delta=   3.1 rho=  0.27 + <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 05:52:13,073 Log likelihood (N = 43812):  -386035.5 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 05:52:13,073 8 f= 0.8542085 projected rel. grad.=   2.7 rel. change=   1.2 delta=   1.6 rho=  -1.1 - <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 05:56:19,005 Log likelihood (N = 43812):  -173124.6 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 05:56:19,006 9 f= 0.8542085 projected rel. grad.=   2.7 rel. change=   1.2 delta=  0.78 rho=  -1.6 - <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 06:00:26,232 Log likelihood (N = 43812):  -81796.77 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 06:00:26,233 10 f= 0.8542085 projected rel. grad.=   2.7 rel. change=   1.2 delta=  0.39 rho=  -1.9 - <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 06:04:32,282 Log likelihood (N = 43812):  -48817.84 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 06:04:32,282 11 f= 0.8542085 projected rel. grad.=   2.7 rel. change=   1.2 delta=   0.2 rho=  -1.5 - <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 06:08:38,460 Log likelihood (N = 43812):  -38705.38 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 06:08:38,460 12 f= 0.8542085 projected rel. grad.=   2.7 rel. change=   1.2 delta= 0.098 rho= -0.43 - <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 06:12:44,678 Log likelihood (N = 43812):  -35857.05 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 07:32:21,409 Log likelihood (N = 43812):  -35857.05 Gradient norm:      9e+04   <biogeme.py:935>\n",
      "[DEBUG] 2024-07-29 07:32:21,411 13 f= 0.8184298 projected rel. grad.=  0.83 rel. change= 0.098 delta= 0.098 rho=  0.66 + <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 07:36:25,390 Log likelihood (N = 43812):  -34977.84 <biogeme.py:853>\n",
      "[DEBUG] 2024-07-29 08:56:03,553 Log likelihood (N = 43812):  -34977.84 Gradient norm:      4e+04   <biogeme.py:935>\n",
      "[DEBUG] 2024-07-29 08:56:03,555 14 f=  0.798362 projected rel. grad.=  0.39 rel. change= 0.042 delta=  0.98 rho=   1.1 ++ <algorithms.py:2012>\n",
      "[DEBUG] 2024-07-29 09:00:18,351 Log likelihood (N = 43812):   -34848.1 <biogeme.py:853>\n"
     ]
    }
   ],
   "source": [
    "## Execute experiments\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "## Initialize dictionaries to store partial results\n",
    "# Load the previous experiment data (deserialize)\n",
    "try:\n",
    "    with open(partial_results_dir + '/Experiment_4_CV_scores.pickle', 'rb') as handle:\n",
    "        Experiment_4_CV_scores = pickle.load(handle)\n",
    "except:\n",
    "    Experiment_4_CV_scores = {}\n",
    "try:\n",
    "    with open(partial_results_dir + '/Experiment_4_test_scores.pickle', 'rb') as handle:\n",
    "        Experiment_4_test_scores = pickle.load(handle)\n",
    "except:\n",
    "    Experiment_4_test_scores = {}\n",
    "\n",
    "dataset_train, dataset_test = return_dataset([load_preprocess_LPMC], to_return = 'split')\n",
    "models_train_rum = prepare_model([LPMC], dataset_train)\n",
    "\n",
    "#rum_structure, nests, and mu\n",
    "rnd_effects_attributes = ['age', 'female', 'start_time_linear', 'travel_day', 'day_of_week', 'car_ownership', 'driving_license', 'purpose_B', 'purpose_HBE', 'purpose_HBO', 'purpose_HBW', 'purpose_NHBO', 'fueltype_Average', 'fueltype_Diesel', 'fueltype_Hybrid', 'fueltype_Petrol']\n",
    "\n",
    "MNL_utilities = {0: 'B_dur_walking_Walk*dur_walking', # + B_age_Walk*age + B_female_Walk*female + B_day_of_week_Walk*day_of_week + B_start_time_linear_Walk*start_time_linear + B_car_ownership_Walk*car_ownership + B_driving_license_Walk*driving_license + B_purpose_B_Walk*purpose_B + B_purpose_HBE_Walk*purpose_HBE + B_purpose_HBO_Walk*purpose_HBO + B_purpose_HBW_Walk*purpose_HBW + B_purpose_NHBO_Walk*purpose_NHBO + B_fueltype_Avrg_Walk*fueltype_Average + B_fueltype_Diesel_Walk*fueltype_Diesel + B_fueltype_Hybrid_Walk*fueltype_Hybrid + B_fueltype_Petrol_Walk*fueltype_Petrol + B_distance_Walk*distance',\n",
    "                    1: 'ASC_Bike + B_age_Bike*age + B_female_Bike*female + B_day_of_week_Bike*day_of_week + B_start_time_linear_Bike*start_time_linear + B_car_ownership_Bike*car_ownership + B_driving_license_Bike*driving_license + B_purpose_B_Bike*purpose_B + B_purpose_HBE_Bike*purpose_HBE + B_purpose_HBO_Bike*purpose_HBO + B_purpose_HBW_Bike*purpose_HBW + B_purpose_NHBO_Bike*purpose_NHBO + B_fueltype_Avrg_Bike*fueltype_Average + B_fueltype_Diesel_Bike*fueltype_Diesel + B_fueltype_Hybrid_Bike*fueltype_Hybrid + B_fueltype_Petrol_Bike*fueltype_Petrol + B_distance_Bike*distance + B_dur_cycling_Bike*dur_cycling',\n",
    "                    2: 'ASC_Public_Transport + B_age_Public_Transport*age + B_female_Public_Transport*female + B_day_of_week_Public_Transport*day_of_week + B_start_time_linear_Public_Transport*start_time_linear + B_car_ownership_Public_Transport*car_ownership + B_driving_license_Public_Transport*driving_license + B_purpose_B_Public_Transport*purpose_B + B_purpose_HBE_Public_Transport*purpose_HBE + B_purpose_HBO_Public_Transport*purpose_HBO + B_purpose_HBW_Public_Transport*purpose_HBW + B_purpose_NHBO_Public_Transport*purpose_NHBO + B_fueltype_Avrg_Public_Transport*fueltype_Average + B_fueltype_Diesel_Public_Transport*fueltype_Diesel + B_fueltype_Hybrid_Public_Transport*fueltype_Hybrid + B_fueltype_Petrol_Public_Transport*fueltype_Petrol + B_distance_Public_Transport*distance + B_dur_pt_access_Public_Transport*dur_pt_access + B_dur_pt_rail_Public_Transport*dur_pt_rail + B_dur_pt_bus_Public_Transport*dur_pt_bus + B_dur_pt_int_waiting_Public_Transport*dur_pt_int_waiting + B_dur_pt_int_walking_Public_Transport*dur_pt_int_walking + B_pt_n_interchanges_Public_Transport*pt_n_interchanges + B_cost_transit_Public_Transport*cost_transit',\n",
    "                    3: 'ASC_Car + B_age_Car*age + B_female_Car*female + B_day_of_week_Car*day_of_week + B_start_time_linear_Car*start_time_linear + B_car_ownership_Car*car_ownership + B_driving_license_Car*driving_license + B_purpose_B_Car*purpose_B + B_purpose_HBE_Car*purpose_HBE + B_purpose_HBO_Car*purpose_HBO + B_purpose_HBW_Car*purpose_HBW + B_purpose_NHBO_Car*purpose_NHBO + B_fueltype_Avrg_Car*fueltype_Average + B_fueltype_Diesel_Car*fueltype_Diesel + B_fueltype_Hybrid_Car*fueltype_Hybrid + B_fueltype_Petrol_Car*fueltype_Petrol + B_distance_Car*distance + B_dur_driving_Car*dur_driving + B_cost_driving_fuel_Car*cost_driving_fuel + B_con_charge_Car*congestion_charge + B_traffic_perc_Car*driving_traffic_percent'}\n",
    "\n",
    "\n",
    "\n",
    "for dataset_id, dataset in datasets.items():\n",
    "    dataset_name = dataset[\"name\"]\n",
    "    print(\"\\n--- {} (ID: {})\".format(dataset_name, dataset_id))\n",
    "\n",
    "    # Load the data and the hyperparameters\n",
    "    X, y, final_test_X, final_test_y, alts, groups, hyperparameters = load_data(dataset_id, dataset)\n",
    "\n",
    "    # Obtain datasets for K-Fold cross validation (the same fold splits are used across all the iterations for all models)\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    crossval_pickle_file = data_dir+dataset_id+\"_crossval.pickle\"\n",
    "    try:\n",
    "        train_indices, test_indices = pickle.load(open(crossval_pickle_file, \"rb\"))\n",
    "        if reset_crossval_indices == 1: # Reset the indices\n",
    "            raise FileNotFoundError\n",
    "    except (OSError, IOError) as e:\n",
    "        print(\"Recomputing Cross-val indices...\")\n",
    "        for (train_index, test_index) in stratified_group_k_fold(X, y, groups, k=CV):\n",
    "            train_indices.append(train_index)\n",
    "            test_indices.append(test_index)\n",
    "        pickle.dump([train_indices, test_indices], open(crossval_pickle_file, \"wb\"))\n",
    "\n",
    "\n",
    "    # Get results for the selected classifier\n",
    "    for classifier in model_type_to_class.keys():\n",
    "        print(\"\\n\\t--- {}\".format(classifier))\n",
    "        sys.stdout.flush()\n",
    "        it_time_init = time.perf_counter()\n",
    "\n",
    "        n_rounds = 0\n",
    "\n",
    "        # Create dictionary to store the results\n",
    "        if not classifier in Experiment_4_CV_scores.keys():\n",
    "            Experiment_4_CV_scores[classifier] = {}\n",
    "        if not classifier in Experiment_4_test_scores.keys():\n",
    "            Experiment_4_test_scores[classifier] = {}\n",
    "\n",
    "        if recompute_Experiment_4==True or not (dataset_name in Experiment_4_CV_scores[classifier].keys()) or not (dataset_name in Experiment_4_test_scores[classifier].keys()):\n",
    "            # Create dictionary to store the results\n",
    "            Experiment_4_CV_scores[classifier][dataset_name] = {}\n",
    "            Experiment_4_CV_scores[classifier][dataset_name]['Accuracy'] = []\n",
    "            Experiment_4_CV_scores[classifier][dataset_name]['F1'] = []\n",
    "            Experiment_4_CV_scores[classifier][dataset_name]['Recall'] = []\n",
    "            Experiment_4_CV_scores[classifier][dataset_name]['GMPCA'] = []\n",
    "            Experiment_4_CV_scores[classifier][dataset_name]['Estimation time'] = []\n",
    "            Experiment_4_test_scores[classifier][dataset_name] = {}\n",
    "\n",
    "            ## Applying k-Fold Cross Validation over training set\n",
    "            for iteration in range(0, len(train_indices)):\n",
    "                print(\"\\t\\t CV it: {}\".format(iteration))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "                # Create the classifier\n",
    "\n",
    "                if classifier == \"RUMBoost\":\n",
    "                    params = copy.deepcopy(STATIC_PARAMS)\n",
    "                    params['max_depth'] = 1\n",
    "                    rum_structure = bio_to_rumboost(models_train_rum[0])\n",
    "                elif classifier == 'RUMBoost_FI':\n",
    "                    params = copy.deepcopy(STATIC_PARAMS)\n",
    "                    params['max_depth'] = 2\n",
    "                    rum_structure = bio_to_rumboost(models_train_rum[0])\n",
    "                    rum_structure[0]['interaction_constraints'] = [[0, 16], [2], [5], [15], [1], [3], [4], [6], [7], [8], [9], [10], [11], [12], [13], [14]]\n",
    "                    rum_structure[1]['interaction_constraints'] = [[0, 16], [2], [5], [15], [1], [3], [4], [6], [7], [8], [9], [10], [11], [12], [13], [14]]\n",
    "                    rum_structure[2]['interaction_constraints'] = [[0, 17], [2], [5], [15], [1], [3], [4], [6], [7], [8], [9], [10], [11], [12], [13], [14], [16], [18], [19], [20], [21], [22]]\n",
    "                    rum_structure[3]['interaction_constraints'] = [[0, 16], [2], [5], [15], [1], [3], [4], [6], [7], [8], [9], [10], [11], [12], [13], [14], [17]]\n",
    "                elif classifier == \"Nested_RUMBoost\":\n",
    "                    params = copy.deepcopy(STATIC_PARAMS)\n",
    "                    params['max_depth'] = 1\n",
    "                    rum_structure = bio_to_rumboost(models_train_rum[0])\n",
    "                    nest = {0:0, 1:1, 2:2, 3:2}\n",
    "                    mu = [1, 1, 1.166746773143513],\n",
    "                elif classifier == 'Cross-nested_RUMBoost':\n",
    "                    params = copy.deepcopy(STATIC_PARAMS)\n",
    "                    params['max_depth'] = 1\n",
    "                    rum_structure = bio_to_rumboost(models_train_rum[0])\n",
    "                    mu = [1.821282482078, 1.000015988]\n",
    "                    alphas = np.array([[0, 1], [0, 1], [1, 0], [0.363528056, 1-0.363528056]])\n",
    "                elif classifier == \"Full_Effect_RUMBoost\":\n",
    "                    params_rde = create_classifier(classifier, hyperparameters, dataset, X, y, for_CV=True)\n",
    "                    rum_structure = bio_to_rumboost(models_train_rum[0], rnd_effect_attributes=rnd_effects_attributes)\n",
    "                    params = {'verbose': -1,\n",
    "                    'num_classes':4,\n",
    "                    'early_stopping_round':100,\n",
    "                    'learning_rate': params['learning_rate'],\n",
    "                    'max_depth': 1,\n",
    "                    #'num_leaves':31,\n",
    "                    'num_boost_round': 3000,\n",
    "                    'objective':'multiclass',\n",
    "                    'boosting': 'gbdt',\n",
    "                    'monotone_constraints_method': 'advanced'}\n",
    "                \n",
    "\n",
    "                # Obtain training and testing data for this iteration (split of de k-Fold)\n",
    "                X_train, X_test = X.loc[train_indices[iteration]], X.loc[test_indices[iteration]]\n",
    "                y_train, y_test = y.loc[train_indices[iteration]], y.loc[test_indices[iteration]]\n",
    "\n",
    "                train_set = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "                test_set = lgb.Dataset(X_test, label=y_test, free_raw_data=False)\n",
    "\n",
    "                if classifier == \"MNL\":\n",
    "                    models_train = prepare_model([LPMC_normalised], [dataset_train[0].loc[train_indices[iteration]]])\n",
    "                if classifier == \"Nested_MNL\":\n",
    "                    models_train = prepare_model([LPMC_nested_normalised], [dataset_train[0].loc[train_indices[iteration]]])\n",
    "                if classifier == \"CNL\":\n",
    "                    models_train = prepare_model([LPMC_cross_nested_normalised], [dataset_train[0].loc[train_indices[iteration]]])\n",
    "                if classifier == \"Mixed Logit\":\n",
    "                    models_train = prepare_model([LPMC_mixed_logit_tt], [dataset_train[0].loc[train_indices[iteration]]])\n",
    "                \n",
    "\n",
    "                # Balance dataset\n",
    "                #X_train, y_train = balance(X_train, y_train, X_train.shape[0], len(dataset[\"alt_names\"]))\n",
    "                time_ini = time.perf_counter()\n",
    "                if classifier == \"RUMBoost\":\n",
    "                    clf_trained = rum_train(params, train_set, rum_structure, valid_sets=[test_set])\n",
    "                    n_rounds += clf_trained.best_iteration\n",
    "                elif classifier == \"Nested_RUMBoost\":\n",
    "                    clf_trained = rum_train(params, train_set, rum_structure, valid_sets=[test_set], nests=nest, mu=mu)\n",
    "                    n_rounds += clf_trained.best_iteration\n",
    "                elif classifier == \"Full_Effect_RUMBoost\":\n",
    "                    clf_trained = rum_train(params, train_set, rum_structure, valid_sets=[test_set], params_rde=params_rde)\n",
    "                    n_rounds += clf_trained.best_iteration\n",
    "                elif classifier == 'Cross-nested_RUMBoost':\n",
    "                    clf_trained = rum_train(params, train_set, rum_structure, valid_sets=[test_set], alphas=alphas, mu=mu)\n",
    "                    n_rounds += clf_trained.best_iteration\n",
    "                elif classifier == \"RUMBoost_FI\":\n",
    "                    clf_trained = rum_train(params, train_set, rum_structure, valid_sets=[test_set])\n",
    "                    n_rounds += clf_trained.best_iteration\n",
    "                elif classifier == \"MNL\":\n",
    "                    clf_trained = estimate_models(models_train)\n",
    "                elif classifier == \"Nested_MNL\":\n",
    "                    clf_trained = estimate_models(models_train)\n",
    "                elif classifier == \"CNL\":\n",
    "                    clf_trained = estimate_models(models_train)\n",
    "                elif classifier == \"Mixed Logit\":\n",
    "                    clf_trained = estimate_models(models_train, mixed_logit=True)\n",
    "                elapsed_time = time.perf_counter() - time_ini\n",
    "\n",
    "                if classifier == \"MNL\":\n",
    "                    proba = predict_proba(dataset_train[0].loc[test_indices[iteration]], clf_trained[0], [0, 1, 2, 3], MNL_utilities)\n",
    "                elif classifier == \"Nested_MNL\":\n",
    "                    labels = prepare_labels([dataset_train[0].loc[test_indices[iteration]]])\n",
    "                    model_test = prepare_model([LPMC_nested_normalised], [dataset_train[0].loc[test_indices[iteration]]], for_prob=True)\n",
    "                    proba = predict_test(clf_trained, model_test, labels, return_prob=True)\n",
    "                elif classifier == \"CNL\":\n",
    "                    labels = prepare_labels([dataset_train[0].loc[test_indices[iteration]]])\n",
    "                    model_test = prepare_model([LPMC_cross_nested_normalised], [dataset_train[0].loc[test_indices[iteration]]], for_prob=True)\n",
    "                    proba = predict_test(clf_trained, model_test, labels, return_prob=True)\n",
    "                elif classifier == \"Mixed Logit\":\n",
    "                    labels = prepare_labels([dataset_train[0].loc[test_indices[iteration]]])\n",
    "                    model_test = prepare_model([LPMC_mixed_logit_tt], [dataset_train[0].loc[test_indices[iteration]]], for_prob=True)\n",
    "                    proba = predict_test(clf_trained, model_test, labels, return_prob=True)\n",
    "                elif classifier == \"Nested_RUMBoost\":\n",
    "                    proba, _, _ = clf_trained.predict(test_set, nests=nest, mu=mu)\n",
    "                elif classifier == 'Cross-nested_RUMBoost':\n",
    "                    proba, _, _ = clf_trained.predict(test_set, alphas=alphas, mu=mu)\n",
    "                else:\n",
    "                    proba = clf_trained.predict(test_set)\n",
    "                y_score = np.argmax(proba, axis=1)\n",
    "\n",
    "                # Compute the accuracy results\n",
    "                Experiment_4_CV_scores[classifier][dataset_name]['Accuracy'] = np.append(Experiment_4_CV_scores[classifier][dataset_name]['Accuracy'], accuracy_score(y_test, y_score)*100)\n",
    "                Experiment_4_CV_scores[classifier][dataset_name]['F1'] = np.append(Experiment_4_CV_scores[classifier][dataset_name]['F1'], f1_score(y_test, y_score, average=average_tech)*100)\n",
    "                Experiment_4_CV_scores[classifier][dataset_name]['Recall'] = np.append(Experiment_4_CV_scores[classifier][dataset_name]['Recall'], recall_score(y_test, y_score, average=average_tech)*100)\n",
    "                Experiment_4_CV_scores[classifier][dataset_name]['GMPCA'] = np.append(Experiment_4_CV_scores[classifier][dataset_name]['GMPCA'], GMPCA(proba, y_test.values)*100)\n",
    "                Experiment_4_CV_scores[classifier][dataset_name]['Estimation time'] = np.append(Experiment_4_CV_scores[classifier][dataset_name]['Estimation time'], elapsed_time)\n",
    "\n",
    "                del clf_trained\n",
    "                gc.collect()\n",
    "\n",
    "            ## Out-of-sample results\n",
    "            # Create the classifier\n",
    "            if classifier == \"RUMBoost\":\n",
    "                params = copy.deepcopy(STATIC_PARAMS)\n",
    "                params['num_iterations'] = int(n_rounds/CV)\n",
    "                params['max_depth'] = 1\n",
    "                rum_structure = bio_to_rumboost(models_train_rum[0])\n",
    "            elif classifier == 'RUMBoost_FI':\n",
    "                params = copy.deepcopy(STATIC_PARAMS)\n",
    "                params['num_iterations'] = int(n_rounds/CV)\n",
    "                params['max_depth'] = 2\n",
    "                rum_structure = bio_to_rumboost(models_train_rum[0])\n",
    "                rum_structure[0]['interaction_constraints'] = [[0, 16], [2], [5], [15], [1], [3], [4], [6], [7], [8], [9], [10], [11], [12], [13], [14]]\n",
    "                rum_structure[1]['interaction_constraints'] = [[0, 16], [2], [5], [15], [1], [3], [4], [6], [7], [8], [9], [10], [11], [12], [13], [14]]\n",
    "                rum_structure[2]['interaction_constraints'] = [[0, 17], [2], [5], [15], [1], [3], [4], [6], [7], [8], [9], [10], [11], [12], [13], [14], [16], [18], [19], [20], [21], [22]]\n",
    "                rum_structure[3]['interaction_constraints'] = [[0, 16], [2], [5], [15], [1], [3], [4], [6], [7], [8], [9], [10], [11], [12], [13], [14], [17]]\n",
    "            elif classifier == \"Nested_RUMBoost\":\n",
    "                params = copy.deepcopy(STATIC_PARAMS)\n",
    "                params['num_iterations'] = int(n_rounds/CV)\n",
    "                params['max_depth'] = 1\n",
    "                rum_structure = bio_to_rumboost(models_train_rum[0])\n",
    "                nest == {0:0, 1:1, 2:2, 3:2}\n",
    "                mu = [1, 1, 1.166746773143513]\n",
    "            elif classifier == 'Cross-nested_RUMBoost':\n",
    "                params = copy.deepcopy(STATIC_PARAMS)\n",
    "                params['num_iterations'] = int(n_rounds/CV)\n",
    "                params['max_depth'] = 1\n",
    "                rum_structure = bio_to_rumboost(models_train_rum[0])\n",
    "                mu = [1.821282482078, 1.000015988]\n",
    "                alphas = np.array([[0, 1], [0, 1], [1, 0], [0.363528056, 1-0.363528056]])\n",
    "            elif classifier == \"Full_Effect_RUMBoost\":\n",
    "                params_rde = create_classifier(classifier, hyperparameters, dataset, X, y, for_CV=True)\n",
    "                params_rde['num_iterations'] = int(n_rounds/CV)\n",
    "                rum_structure = bio_to_rumboost(models_train_rum[0], rnd_effect_attributes=rnd_effects_attributes)\n",
    "                params = {'verbose': -1,\n",
    "                'num_classes':4,\n",
    "                #'early_stopping_round':100,\n",
    "                'learning_rate': 0.1,\n",
    "                'max_depth': 1,\n",
    "                #'num_leaves':31,\n",
    "                'num_iterations': int(n_rounds/CV),\n",
    "                'objective':'multiclass',\n",
    "                'boosting': 'gbdt',\n",
    "                'monotone_constraints_method': 'advanced'}\n",
    "\n",
    "            train_set = lgb.Dataset(X, label=y, free_raw_data=False)\n",
    "            test_set = lgb.Dataset(final_test_X, label=final_test_y, free_raw_data=False)\n",
    "\n",
    "            # Balance dataset\n",
    "            #X_scaled_balanced, y_balanced = balance(X_scaled, y, X_scaled.shape[0], len(dataset[\"alt_names\"]))\n",
    "            if classifier == \"MNL\":\n",
    "                models_train = prepare_model([LPMC_normalised], dataset_train)\n",
    "            elif classifier == \"Nested_MNL\":\n",
    "                models_train = prepare_model([LPMC_nested_normalised], dataset_train)\n",
    "            elif classifier == \"CNL\":\n",
    "                models_train = prepare_model([LPMC_cross_nested_normalised], dataset_train)\n",
    "            elif classifier == \"Mixed Logit\":\n",
    "                models_train = prepare_model([LPMC_mixed_logit_tt], dataset_train)\n",
    "\n",
    "            # Fit the classifier on training set\n",
    "            time_ini = time.perf_counter()\n",
    "            if classifier == \"RUMBoost\":\n",
    "                clf_trained = rum_train(params, train_set, rum_structure, valid_sets=[train_set])\n",
    "            elif classifier == \"Nested_RUMBoost\":\n",
    "                clf_trained = rum_train(params, train_set, rum_structure, valid_sets=[train_set], nests=nest, mu=mu)\n",
    "            elif classifier == 'Cross-nested_RUMBoost':\n",
    "                clf_trained = rum_train(params, train_set, rum_structure, valid_sets=[test_set], alphas=alphas, mu=mu)\n",
    "            elif classifier == \"Full_Effect_RUMBoost\":\n",
    "                clf_trained = rum_train(params, train_set, rum_structure, valid_sets=[train_set], params_rde=params_rde)\n",
    "            elif classifier == \"RUMBoost_FI\":\n",
    "                clf_trained = rum_train(params, train_set, rum_structure, valid_sets=[train_set])\n",
    "            elif classifier == \"MNL\":\n",
    "                clf_trained = estimate_models(models_train)\n",
    "            elif classifier == \"Nested_MNL\":\n",
    "                clf_trained = estimate_models(models_train)\n",
    "            elif classifier == \"CNL\":\n",
    "                clf_trained = estimate_models(models_train)\n",
    "            elif classifier == \"Mixed Logit\":\n",
    "                clf_trained = estimate_models(models_train, mixed_logit=True)\n",
    "            elapsed_time = time.perf_counter() - time_ini\n",
    "\n",
    "            if classifier == \"MNL\":\n",
    "                proba = predict_proba(dataset_test[0], clf_trained[0], [0, 1, 2, 3], MNL_utilities)\n",
    "            elif classifier == \"Nested_MNL\":\n",
    "                labels = prepare_labels(dataset_test)\n",
    "                model_test = prepare_model([LPMC_nested_normalised], dataset_test, for_prob=True)\n",
    "                proba = predict_test(clf_trained, model_test, labels, return_prob=True)\n",
    "            elif classifier == \"CNL\":\n",
    "                labels = prepare_labels(dataset_test)\n",
    "                model_test = prepare_model([LPMC_cross_nested_normalised], dataset_test, for_prob=True)\n",
    "                proba = predict_test(clf_trained, model_test, labels, return_prob=True)\n",
    "            elif classifier == \"Mixed Logit\":\n",
    "                labels = prepare_labels(dataset_test)\n",
    "                model_test = prepare_model([LPMC_mixed_logit_tt], dataset_test, for_prob=True)\n",
    "                proba = predict_test(clf_trained, model_test, labels, return_prob=True)\n",
    "            elif classifier == \"Nested_RUMBoost\":\n",
    "                proba, _, _ = clf_trained.predict(test_set, nests=nest, mu=mu)\n",
    "            elif classifier == 'Cross-nested_RUMBoost':\n",
    "                proba, _, _ = clf_trained.predict(test_set, alphas=alphas, mu=mu)\n",
    "            else:\n",
    "                proba = clf_trained.predict(test_set)\n",
    "            \n",
    "            fitted = True\n",
    "            \n",
    "            if classifier == \"RUMBoost\":\n",
    "                clf_trained.save_model(partial_results_dir + \"LPMC_RUMBoost.json\")\n",
    "            elif classifier == \"Nested_RUMBoost\":\n",
    "                clf_trained.save_model(partial_results_dir + \"LPMC_RUMBoost_Nested.json\")\n",
    "            elif classifier == 'Cross-nested_RUMBoost':\n",
    "                clf_trained.save_model(partial_results_dir + \"LPMC_RUMBoost_Cross-nested.json\")\n",
    "            elif classifier == \"Full_Effect_RUMBoost\":\n",
    "                clf_trained.save_model(partial_results_dir + \"LPMC_RUMBoost_Full_Effect.json\")\n",
    "            elif classifier == \"RUMBoost_FI\":\n",
    "                clf_trained.save_model(partial_results_dir + \"LPMC_RUMBoost_FI.json\")\n",
    "            elif classifier == \"MNL\":\n",
    "                pandas_results = clf_trained[0].getEstimatedParameters()\n",
    "                pandas_results.to_csv(partial_results_dir + 'LPMC_MNL.csv')\n",
    "            elif classifier == \"Nested_MNL\":\n",
    "                pandas_results = clf_trained[0].getEstimatedParameters()\n",
    "                pandas_results.to_csv(partial_results_dir + 'LPMC_NL.csv')\n",
    "            elif classifier == \"CNL\":\n",
    "                pandas_results = clf_trained[0].getEstimatedParameters()\n",
    "                pandas_results.to_csv(partial_results_dir + 'LPMC_CNL.csv')\n",
    "\n",
    "\n",
    "            y_score = np.argmax(proba, axis=1)\n",
    "\n",
    "            # Compute the accuracy results\n",
    "            Experiment_4_test_scores[classifier][dataset_name]['Accuracy'] = accuracy_score(final_test_y, y_score)*100\n",
    "            Experiment_4_test_scores[classifier][dataset_name]['F1'] = f1_score(final_test_y, y_score, average=average_tech)*100\n",
    "            Experiment_4_test_scores[classifier][dataset_name]['Recall'] = recall_score(final_test_y, y_score, average=average_tech)*100\n",
    "            Experiment_4_test_scores[classifier][dataset_name]['GMPCA'] = GMPCA(proba, final_test_y.values)*100\n",
    "            Experiment_4_test_scores[classifier][dataset_name]['Estimation time'] = elapsed_time\n",
    "\n",
    "            ## Market shares\n",
    "            #Experiment_4_CV_scores[classifier][dataset_name]['Market_shares'] = np.round(np.sum(clf.predict_proba(X_scaled), axis=0)/X_scaled.shape[0] * 100, 3)\n",
    "            #Experiment_4_test_scores[classifier][dataset_name]['Market_shares'] = np.round(np.sum(clf.predict_proba(final_test_X_scaled), axis=0)/final_test_X_scaled.shape[0] * 100, 3)\n",
    "            \n",
    "            ## WTP\n",
    "            #Experiment_4_CV_scores[classifier][dataset_name][\"WTP_history\"] = None\n",
    "            #Experiment_4_test_scores[classifier][dataset_name][\"WTP_history\"] = None\n",
    "            # if dataset[\"WTP\"] is not None:\n",
    "            #     Experiment_4_CV_scores[classifier][dataset_name][\"WTP_history\"] = {}\n",
    "            #     Experiment_4_CV_scores[classifier][dataset_name][\"n_WTP_nan\"] = 0\n",
    "            #     Experiment_4_CV_scores[classifier][dataset_name][\"n_WTP_inf\"] = 0\n",
    "            #     Experiment_4_test_scores[classifier][dataset_name][\"WTP_history\"] = {}\n",
    "            #     Experiment_4_test_scores[classifier][dataset_name][\"n_WTP_nan\"] = 0\n",
    "            #     Experiment_4_test_scores[classifier][dataset_name][\"n_WTP_inf\"] = 0\n",
    "\n",
    "            #     for alt in dataset[\"WTP\"].keys():\n",
    "            #         v1_name, v2_name, d_1, d_2 = dataset[\"WTP\"][alt]\n",
    "\n",
    "            #         # WTP over training set \n",
    "            #         filtered_WTP, n_WTP_nan, n_WTP_inf = compute_WTP(clf, dataset, X, v1_name, v2_name, d_1, d_2, scaler)\n",
    "            #         Experiment_4_CV_scores[classifier][dataset_name][\"n_WTP_nan\"] += n_WTP_nan\n",
    "            #         Experiment_4_CV_scores[classifier][dataset_name][\"n_WTP_inf\"] += n_WTP_inf\n",
    "            #         Experiment_4_CV_scores[classifier][dataset_name][\"WTP_history\"][dataset[\"alt_names\"][alt]] = filtered_WTP\n",
    "\n",
    "            #         # WTP over test set \n",
    "            #         filtered_WTP, n_WTP_nan, n_WTP_inf = compute_WTP(clf, dataset, final_test_X, v1_name, v2_name, d_1, d_2, scaler)\n",
    "            #         Experiment_4_test_scores[classifier][dataset_name][\"n_WTP_nan\"] += n_WTP_nan\n",
    "            #         Experiment_4_test_scores[classifier][dataset_name][\"n_WTP_inf\"] += n_WTP_inf\n",
    "            #         Experiment_4_test_scores[classifier][dataset_name][\"WTP_history\"][dataset[\"alt_names\"][alt]] = filtered_WTP\n",
    "\n",
    "            del clf_trained\n",
    "            gc.collect()\n",
    "\n",
    "        # Store the partial experiment data (serialize)\n",
    "        with open(partial_results_dir + 'Experiment_4_CV_scores.pickle', 'wb') as handle:\n",
    "            pickle.dump(Experiment_4_CV_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(partial_results_dir + 'Experiment_4_test_scores.pickle', 'wb') as handle:\n",
    "            pickle.dump(Experiment_4_test_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print(\"\\t    + Elapsed: {} seconds\".format(np.round(time.perf_counter()-it_time_init), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export LaTeX tables/figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(partial_results_dir + '/Experiment_4_CV_scores_all.pickle', 'rb') as handle:\n",
    "        Experiment_4_CV_scores = pickle.load(handle)\n",
    "except:\n",
    "    Experiment_4_CV_scores = {}\n",
    "try:\n",
    "    with open(partial_results_dir + '/Experiment_4_test_scores_all.pickle', 'rb') as handle:\n",
    "        Experiment_4_test_scores = pickle.load(handle)\n",
    "except:\n",
    "    Experiment_4_test_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain accuracy tables\n",
    "Experiment_4_CV_table, Experiment_4_test_table, Experiment_4_time_table = construct_experiment_4_accuracy_table(Experiment_4_CV_scores, Experiment_4_test_scores)\n",
    "\n",
    "# Obtain market shares table over the test set\n",
    "#Experiment_4_MS_table = construct_experiment_4_market_shares_table(Experiment_4_test_scores, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">RUMBoost</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Nested_RUMBoost</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Cross-nested_RUMBoost</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Full_Effect_RUMBoost</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RUMBoost_FI</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MNL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Nested_MNL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CNL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPMC</th>\n",
       "      <td>74.76</td>\n",
       "      <td>51.84</td>\n",
       "      <td>74.76</td>\n",
       "      <td>51.85</td>\n",
       "      <td>74.86</td>\n",
       "      <td>51.96</td>\n",
       "      <td>75.44</td>\n",
       "      <td>52.48</td>\n",
       "      <td>74.42</td>\n",
       "      <td>51.28</td>\n",
       "      <td>73.31</td>\n",
       "      <td>50.09</td>\n",
       "      <td>73.41</td>\n",
       "      <td>50.05</td>\n",
       "      <td>73.43</td>\n",
       "      <td>50.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RUMBoost        Nested_RUMBoost        Cross-nested_RUMBoost         \\\n",
       "     Accuracy  GMPCA        Accuracy  GMPCA              Accuracy  GMPCA   \n",
       "LPMC    74.76  51.84           74.76  51.85                 74.86  51.96   \n",
       "\n",
       "     Full_Effect_RUMBoost        RUMBoost_FI             MNL         \\\n",
       "                 Accuracy  GMPCA    Accuracy  GMPCA Accuracy  GMPCA   \n",
       "LPMC                75.44  52.48       74.42  51.28    73.31  50.09   \n",
       "\n",
       "     Nested_MNL             CNL         \n",
       "       Accuracy  GMPCA Accuracy  GMPCA  \n",
       "LPMC      73.41  50.05    73.43  50.12  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment_4_CV_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">RUMBoost</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Nested_RUMBoost</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Cross-nested_RUMBoost</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Full_Effect_RUMBoost</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RUMBoost_FI</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MNL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Nested_MNL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CNL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPMC</th>\n",
       "      <td>74.15</td>\n",
       "      <td>50.98</td>\n",
       "      <td>74.15</td>\n",
       "      <td>51.01</td>\n",
       "      <td>74.1</td>\n",
       "      <td>51.09</td>\n",
       "      <td>74.64</td>\n",
       "      <td>51.55</td>\n",
       "      <td>73.6</td>\n",
       "      <td>50.39</td>\n",
       "      <td>72.69</td>\n",
       "      <td>49.24</td>\n",
       "      <td>72.77</td>\n",
       "      <td>49.21</td>\n",
       "      <td>72.93</td>\n",
       "      <td>49.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RUMBoost        Nested_RUMBoost        Cross-nested_RUMBoost         \\\n",
       "     Accuracy  GMPCA        Accuracy  GMPCA              Accuracy  GMPCA   \n",
       "LPMC    74.15  50.98           74.15  51.01                  74.1  51.09   \n",
       "\n",
       "     Full_Effect_RUMBoost        RUMBoost_FI             MNL         \\\n",
       "                 Accuracy  GMPCA    Accuracy  GMPCA Accuracy  GMPCA   \n",
       "LPMC                74.64  51.55        73.6  50.39    72.69  49.24   \n",
       "\n",
       "     Nested_MNL             CNL         \n",
       "       Accuracy  GMPCA Accuracy  GMPCA  \n",
       "LPMC      72.77  49.21    72.93  49.31  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment_4_test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUMBoost</th>\n",
       "      <th>Nested_RUMBoost</th>\n",
       "      <th>Cross-nested_RUMBoost</th>\n",
       "      <th>Full_Effect_RUMBoost</th>\n",
       "      <th>RUMBoost_FI</th>\n",
       "      <th>MNL</th>\n",
       "      <th>Nested_MNL</th>\n",
       "      <th>CNL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPMC</th>\n",
       "      <td>7.86</td>\n",
       "      <td>48.53</td>\n",
       "      <td>183.91</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.01</td>\n",
       "      <td>242.14</td>\n",
       "      <td>1067.04</td>\n",
       "      <td>5120.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RUMBoost Nested_RUMBoost Cross-nested_RUMBoost Full_Effect_RUMBoost  \\\n",
       "LPMC     7.86           48.53                183.91                 10.9   \n",
       "\n",
       "     RUMBoost_FI     MNL Nested_MNL      CNL  \n",
       "LPMC        5.01  242.14    1067.04  5120.01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment_4_time_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
