{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4 on real datasets.\n",
    "**Authors:**\n",
    "* José Ángel Martín-Baos\n",
    "* Julio Alberto López-Gomez\n",
    "* Luis Rodríguez-Benítez\n",
    "* Tim Hillel\n",
    "* Ricardo García-Ródenas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "## Import packages\n",
    "import pandas as pd  # For file input/output\n",
    "from scipy import optimize\n",
    "from scipy.optimize._numdiff import approx_derivative\n",
    "import sys\n",
    "\n",
    "# append a new directory to sys.path\n",
    "sys.path.append('../rumboost and RUMs/')\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import shap\n",
    "from rumbooster import rum_train\n",
    "from utils import bio_to_rumboost\n",
    "from datasets import load_preprocess_LPMC, load_preprocess_SwissMetro\n",
    "from models import LPMC, LPMC_normalised, LPMC_nested_normalised, SwissMetro, SwissMetro_normalised\n",
    "from benchmarks import return_dataset, prepare_model, estimate_models, prepare_labels, predict_test, predict_proba\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Load common functions for the experiments\n",
    "from expermients_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DAF1\\anaconda3\\anaconda3\\envs\\RUMBooster\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Import the Classification models\n",
    "# from Models.MNL import MNL\n",
    "# from Models.SVM import SVM\n",
    "# from Models.RandomForest import RandomForest\n",
    "from Models.LightGBM import LightGBM\n",
    "from Models.NN import NN\n",
    "from Models.DNN import DNN\n",
    "from Models.ResLogit import ResLogit\n",
    "#from Models.CNN import CNN\n",
    "# from Models.ResNet import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize matplotlib\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    \"text.usetex\": True, \n",
    "    \"font.family\": \"serif\",\n",
    "    # Use 14pt font in plots, to match 10pt font in document\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"font.size\": 14,\n",
    "    # Make the legend/label fonts a little smaller\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12\n",
    "}\n",
    "\n",
    "plt.rcParams.update(tex_fonts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment parameters\n",
    "data_dir = \"../Data/Datasets/preprocessed/\"\n",
    "adjusted_hyperparms_dir = \"../Data/adjusted-hyperparameters/\"\n",
    "train_suffix = \"_train.csv\"\n",
    "test_suffix = \"_test.csv\"\n",
    "hyperparameters_suffix = \"_hyperparameters\"\n",
    "reset_crossval_indices = 0 # Set to 0 for reproducibility of the experiment over multiple executions\n",
    "partial_results_dir = \"../Data/Results-RealDatasets/\"\n",
    "\n",
    "recompute_Experiment_4 = True\n",
    "\n",
    "rounding = 2\n",
    "\n",
    "CV = 5 # Number of cross-validation\n",
    "n_iter = 20 #  Number of iterations used on the random search\n",
    "average_tech = \"macro\" #\"micro\"\n",
    "\n",
    "hyperparameters_suffix = hyperparameters_suffix +'_'+ str(n_iter) + '.csv'\n",
    "\n",
    "model_type_to_class = {\"LightGBM\": LightGBM,\n",
    "                       \"NN\": NN,\n",
    "                       \"DNN\": DNN,\n",
    "                       \"ResLogit\": \"ResLogit\"\n",
    "                      }\n",
    "\n",
    "STATIC_PARAMS = {'n_jobs': -1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"LPMC\": {\n",
    "                  \"name\": \"LPMC\",\n",
    "                  \"mode_var\": \"travel_mode\",\n",
    "                  \"individual_id\": \"household_id\",\n",
    "                  \"scaled_fetures\": ['day_of_week', 'start_time_linear', 'age', 'car_ownership',\n",
    "                                     'distance', 'dur_walking', 'dur_cycling', 'dur_pt_access', 'dur_pt_rail',\n",
    "                                     'dur_pt_bus', 'dur_pt_int_waiting', 'dur_pt_int_walking', 'pt_n_interchanges',\n",
    "                                     'dur_driving', 'cost_transit', 'cost_driving_fuel'],\n",
    "                  \"alt_names\": [\"Walk\", \"Bike\", \"Public transport\", \"Car\"]\n",
    "                }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data\n",
    "def load_data(dataset_id, dataset):\n",
    "    train = pd.read_csv(data_dir + dataset_id + train_suffix, sep=',')\n",
    "    final_test = pd.read_csv(data_dir + dataset_id + test_suffix, sep=',')\n",
    "\n",
    "    # Divide the dataset into charasteristics and target variable\n",
    "    X = train.loc[:, train.columns != dataset[\"mode_var\"]]\n",
    "    y = train[dataset[\"mode_var\"]]\n",
    "    final_test_X = final_test.loc[:, final_test.columns != dataset[\"mode_var\"]]\n",
    "    final_test_y = final_test[dataset[\"mode_var\"]]\n",
    "\n",
    "    alts = list(y.unique()) # List containing al the modes (alternatives) in the dataset\n",
    "\n",
    "    # Extract the individual ID to later group observations using it\n",
    "    groups = np.array(X[dataset[\"individual_id\"]].values)\n",
    "    X = X.drop(columns=dataset[\"individual_id\"])\n",
    "    final_test_X = final_test_X.drop(columns=dataset[\"individual_id\"])\n",
    "\n",
    "    # Load the hyperparameters\n",
    "    try:\n",
    "        adjusted_hyperparameters_file = pd.read_csv(adjusted_hyperparms_dir + dataset_id + hyperparameters_suffix , index_col=0)\n",
    "        hyperparameters = adjusted_hyperparameters_file.to_dict()\n",
    "    except (OSError, IOError) as e:\n",
    "        print(\"Error while loading best_hyperparameters for dataset {} - {}...\".format(dataset_id, n_iter))\n",
    "        pass\n",
    "\n",
    "    return (X, y, final_test_X, final_test_y, alts, groups, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-compute all the data for the experiments\n",
    "def pre_compute_data(X, v1_name, v2_name, d_1, d_2):\n",
    "    # Obtain delta \n",
    "    X_std = np.std(X[[v1_name, v2_name]]).to_numpy()\n",
    "    v1_delta = d_1 * X_std[0]\n",
    "    v2_delta = d_2 * X_std[1]\n",
    "\n",
    "    # Obtain pre-computed datasets for numerical differentiation \n",
    "    # Numerical differentiation for v_1\n",
    "    X_v1_minus_d, X_v1_plus_d = X.copy(), X.copy()\n",
    "    X_v1_minus_d[v1_name] = X_v1_minus_d[v1_name] - v1_delta\n",
    "    X_v1_plus_d[v1_name] = X_v1_plus_d[v1_name] + v1_delta\n",
    "\n",
    "    # Numerical differentiation for v_2\n",
    "    X_v2_minus_d, X_v2_plus_d = X.copy(), X.copy()\n",
    "    X_v2_minus_d[v2_name] = X_v2_minus_d[v2_name] - v2_delta\n",
    "    X_v2_plus_d[v2_name] = X_v2_plus_d[v2_name] + v2_delta\n",
    "\n",
    "    return (X_v1_minus_d, X_v1_plus_d, X_v2_minus_d, X_v2_plus_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_spec_data(dataset):\n",
    "\n",
    "    dataset['zeros'] = np.zeros_like(dataset['distance'])\n",
    "\n",
    "    dataset_alt_spec = np.stack(\n",
    "        [dataset[['distance',  'zeros',    'zeros',    'zeros',    'dur_walking',  'zeros',        'zeros',        'zeros',        'zeros',        'zeros',        'zeros',                'zeros',                'zeros',            'zeros',        'zeros',            'zeros',            'zeros',                    'age', 'female', 'start_time_linear', 'day_of_week', 'car_ownership', 'driving_license', 'purpose_B', 'purpose_HBE', 'purpose_HBO', 'purpose_HBW', 'purpose_NHBO', 'fueltype_Average', 'fueltype_Diesel', 'fueltype_Hybrid', 'fueltype_Petrol']].values,\n",
    "        dataset[['zeros',      'distance', 'zeros',    'zeros',    'zeros',        'dur_cycling',  'zeros',        'zeros',        'zeros',        'zeros',        'zeros',                'zeros',                'zeros',            'zeros',        'zeros',            'zeros',            'zeros',                    'age', 'female', 'start_time_linear', 'day_of_week', 'car_ownership', 'driving_license', 'purpose_B', 'purpose_HBE', 'purpose_HBO', 'purpose_HBW', 'purpose_NHBO', 'fueltype_Average', 'fueltype_Diesel', 'fueltype_Hybrid', 'fueltype_Petrol']].values,\n",
    "        dataset[['zeros',      'zeros',    'distance', 'zeros',    'zeros',        'zeros',        'dur_pt_access','zeros',        'dur_pt_rail',  'dur_pt_bus',   'dur_pt_int_waiting',   'dur_pt_int_walking',   'pt_n_interchanges','cost_transit', 'zeros',            'zeros',            'zeros',                    'age', 'female', 'start_time_linear', 'day_of_week', 'car_ownership', 'driving_license', 'purpose_B', 'purpose_HBE', 'purpose_HBO', 'purpose_HBW', 'purpose_NHBO', 'fueltype_Average', 'fueltype_Diesel', 'fueltype_Hybrid', 'fueltype_Petrol']].values,\n",
    "        dataset[['zeros',      'zeros',    'zeros',    'distance', 'zeros',        'zeros',        'zeros',        'dur_driving',  'zeros',        'zeros',        'zeros',                'zeros',                'zeros',            'zeros',        'cost_driving_fuel','congestion_charge','driving_traffic_percent',  'age', 'female', 'start_time_linear', 'day_of_week', 'car_ownership', 'driving_license', 'purpose_B', 'purpose_HBE', 'purpose_HBO', 'purpose_HBW', 'purpose_NHBO', 'fueltype_Average', 'fueltype_Diesel', 'fueltype_Hybrid', 'fueltype_Petrol']].values]\n",
    "        )\n",
    "    \n",
    "    dataset_alt_spec = np.swapaxes(dataset_alt_spec, 0, 2)\n",
    "    dataset_alt_spec = np.swapaxes(dataset_alt_spec, 0, 1)\n",
    "\n",
    "    return dataset_alt_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the classifier\n",
    "def create_classifier(classifier, hyperparameters, dataset, X, y, for_CV=False):\n",
    "    clf_hyperparameters = copy.deepcopy(hyperparameters)\n",
    "    integer_params = ['max_bin','min_data_in_leaf','num_leaves','num_iterations','hidden_layer_sizes', 'epochs', 'batch_size']\n",
    "    float_params = ['bagging_fraction','feature_fraction','lambda_l1','lambda_l2','min_gain_to_split','min_sum_hessian_in_leaf']\n",
    "    choice_params = {\"learning_rate\": [\"adaptive\"], # NN\n",
    "                    \"max_iter\": [10000000], # NN\n",
    "                    \"tol\": [1e-3], # NN\n",
    "                    \"input_dim\": [X.shape[1]], # DNN, CNN, ResNet\n",
    "                    \"output_dim\": [y.nunique()], # DNN, CNN, ResNet\n",
    "                    #\"depth\": [2,3,4,5,6,7,8,9,10], # DNN\n",
    "                    \"depth\": [4, 8, 16, 32],\n",
    "                    #\"drop\": hyperopt.hp.choice('drop', [0.5, 0.3, 0.1]),\n",
    "                    # TODO: Consider adding the activation functions for the hidden layers (thanh, ReLU, LeakyReLU, etc.)\n",
    "                    \"epochs\": [200],\n",
    "                    \"width\": [25,50,100,150,200], # DNN, ResNet\n",
    "                    \"drop\": [0.1, 0.01, 1e-5], # DNN, ResNet\n",
    "                    \"activation\": [\"tanh\"], # NN\n",
    "                    \"solver\": [\"lbfgs\",\"sgd\",\"adam\"], # NN\n",
    "                    \"batch_size\": [64,128,256], # NN, DNN, CNN,\n",
    "                    \"bagging_freq\": [1, 5, 10]\n",
    "                    }\n",
    "\n",
    "    static_params = copy.deepcopy(STATIC_PARAMS)\n",
    "    \n",
    "    for k in list(clf_hyperparameters[classifier].keys()):\n",
    "        if k.startswith('_'):\n",
    "            del clf_hyperparameters[classifier][k]\n",
    "            continue\n",
    "        if np.isnan(clf_hyperparameters[classifier][k]):\n",
    "            del clf_hyperparameters[classifier][k]\n",
    "            continue\n",
    "        if k in integer_params:\n",
    "            clf_hyperparameters[classifier][k] = int(clf_hyperparameters[classifier][k])\n",
    "        if k in float_params:\n",
    "            clf_hyperparameters[classifier][k] = clf_hyperparameters[classifier][k]\n",
    "        if k in choice_params.keys():\n",
    "            clf_hyperparameters[classifier][k] = choice_params[k][int(clf_hyperparameters[classifier][k])]\n",
    "\n",
    "    params = {**clf_hyperparameters[classifier], **static_params}\n",
    "    if classifier not in [\"RUMBoost\", \"ResLogit\"]:\n",
    "        base_clf = model_type_to_class[classifier](**params)\n",
    "    \n",
    "        return base_clf\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4.1: Which is the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct Experiment 4 - Accuracy, GMPCA and Time Tables\n",
    "def construct_experiment_4_accuracy_table(Experiment_4_CV_scores, Experiment_4_test_scores):\n",
    "    columns = [\"Accuracy\", \"GMPCA\"]\n",
    "\n",
    "    # Compute the mean of all the stored results for all the models and construct the final table\n",
    "    train_scores_df = {}\n",
    "    test_scores_df = {}\n",
    "    time_scores_df = {}\n",
    "\n",
    "    Experiment_4_CV_scores_mean = copy.deepcopy(Experiment_4_CV_scores)\n",
    "    Experiment_4_test_scores_round = copy.deepcopy(Experiment_4_test_scores)\n",
    "    for k_clf in model_type_to_class.keys():\n",
    "        for k_dataset in Experiment_4_CV_scores_mean[k_clf].keys():\n",
    "            for k_score in Experiment_4_CV_scores_mean[k_clf][k_dataset].keys():\n",
    "                if k_score in columns + ['Estimation time']:\n",
    "                    Experiment_4_CV_scores_mean[k_clf][k_dataset][k_score] = np.round(np.mean(Experiment_4_CV_scores_mean[k_clf][k_dataset][k_score]), rounding)\n",
    "                    Experiment_4_test_scores_round[k_clf][k_dataset][k_score] = np.round(Experiment_4_test_scores_round[k_clf][k_dataset][k_score], rounding)\n",
    "        \n",
    "        train_scores_df[k_clf] = pd.DataFrame(Experiment_4_CV_scores_mean[k_clf]).T[columns]\n",
    "        test_scores_df[k_clf] = pd.DataFrame(Experiment_4_test_scores_round[k_clf]).T[columns]\n",
    "        time_scores_df[k_clf] = pd.DataFrame(Experiment_4_CV_scores_mean[k_clf]).T['Estimation time']\n",
    "        \n",
    "    Experiment_4_CV_table = pd.concat(train_scores_df, axis=1)\n",
    "    Experiment_4_test_table = pd.concat(test_scores_df, axis=1)\n",
    "    Experiment_4_time_table = pd.concat(time_scores_df, axis=1)\n",
    "\n",
    "    return (Experiment_4_CV_table, Experiment_4_test_table, Experiment_4_time_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LPMC (ID: LPMC)\n",
      "\n",
      "\t--- ResLogit\n",
      "\t\t CV it: 0\n",
      "Epoch 1: valid_loss = 0.7972640144569566\n",
      "          train_loss = 0.9620987111121247\n",
      "Epoch 2: valid_loss = 0.7269777059413449\n",
      "          train_loss = 0.7635602600430759\n",
      "Epoch 3: valid_loss = 0.7018058236436087\n",
      "          train_loss = 0.7258568796197554\n",
      "Epoch 4: valid_loss = 0.6935461562854836\n",
      "          train_loss = 0.7119344251738464\n",
      "Epoch 5: valid_loss = 0.6862455663606766\n",
      "          train_loss = 0.7041301078232852\n",
      "Epoch 6: valid_loss = 0.6813018753691024\n",
      "          train_loss = 0.6984554352766105\n",
      "Epoch 7: valid_loss = 0.6778471896654652\n",
      "          train_loss = 0.6949305066688698\n",
      "Epoch 8: valid_loss = 0.6763336133859664\n",
      "          train_loss = 0.6923468506865209\n",
      "Epoch 9: valid_loss = 0.6757879939840455\n",
      "          train_loss = 0.6904557271874698\n",
      "Epoch 10: valid_loss = 0.6734899252645855\n",
      "          train_loss = 0.6889812533514382\n",
      "Epoch 11: valid_loss = 0.67288687342384\n",
      "          train_loss = 0.6875375285138196\n",
      "Epoch 12: valid_loss = 0.6731619661956276\n",
      "          train_loss = 0.6866479673675107\n",
      "Epoch 13: valid_loss = 0.6715405960262627\n",
      "          train_loss = 0.6858733747445387\n",
      "Epoch 14: valid_loss = 0.6707405122130363\n",
      "          train_loss = 0.6851744339727636\n",
      "Epoch 15: valid_loss = 0.669858041020396\n",
      "          train_loss = 0.6841806339691718\n",
      "Epoch 16: valid_loss = 0.6691761230898783\n",
      "          train_loss = 0.6835504016182646\n",
      "Epoch 17: valid_loss = 0.6704040753404973\n",
      "          train_loss = 0.6825739513205559\n",
      "Epoch 18: valid_loss = 0.6679759983875413\n",
      "          train_loss = 0.6816965264646919\n",
      "Epoch 19: valid_loss = 0.6670580984427025\n",
      "          train_loss = 0.6809485369771618\n",
      "Epoch 20: valid_loss = 0.6661096049022797\n",
      "          train_loss = 0.6804201191023492\n",
      "Epoch 21: valid_loss = 0.6676642708162079\n",
      "          train_loss = 0.6794021583864172\n",
      "Epoch 22: valid_loss = 0.6653198780453696\n",
      "          train_loss = 0.6787381527797778\n",
      "Epoch 23: valid_loss = 0.66462141638004\n",
      "          train_loss = 0.6777531001714184\n",
      "Epoch 24: valid_loss = 0.6650283012860062\n",
      "          train_loss = 0.6769849933642177\n",
      "Epoch 25: valid_loss = 0.6639226495042626\n",
      "          train_loss = 0.675946111746272\n",
      "Epoch 26: valid_loss = 0.6648046626955976\n",
      "          train_loss = 0.6755266984684728\n",
      "Epoch 27: valid_loss = 0.6639454166991822\n",
      "          train_loss = 0.6751251802450163\n",
      "Epoch 28: valid_loss = 0.6631532773107636\n",
      "          train_loss = 0.6746235309484686\n",
      "Epoch 29: valid_loss = 0.6648822276138358\n",
      "          train_loss = 0.6745813295830253\n",
      "Epoch 30: valid_loss = 0.6639409834459831\n",
      "          train_loss = 0.6740264455423174\n",
      "Epoch 31: valid_loss = 0.6632292440231764\n",
      "          train_loss = 0.6739271929854762\n",
      "Epoch 32: valid_loss = 0.6648538285589382\n",
      "          train_loss = 0.6736150152626373\n",
      "Epoch 33: valid_loss = 0.66377778128222\n",
      "          train_loss = 0.6733481403135134\n",
      "Epoch 34: valid_loss = 0.6630414303084424\n",
      "          train_loss = 0.6735191225482613\n",
      "Epoch 35: valid_loss = 0.6641013636885184\n",
      "          train_loss = 0.6726693212181507\n",
      "Epoch 36: valid_loss = 0.6635149800314978\n",
      "          train_loss = 0.6728971572482786\n",
      "Epoch 37: valid_loss = 0.6654588391587238\n",
      "          train_loss = 0.6725051888959711\n",
      "Epoch 38: valid_loss = 0.6627178283629254\n",
      "          train_loss = 0.6725326173773722\n",
      "Epoch 39: valid_loss = 0.664248435164742\n",
      "          train_loss = 0.6721634705738807\n",
      "Epoch 40: valid_loss = 0.66317302513083\n",
      "          train_loss = 0.6723388567747403\n",
      "Epoch 41: valid_loss = 0.6633233045044983\n",
      "          train_loss = 0.6718021732084501\n",
      "Epoch 42: valid_loss = 0.6615423941942774\n",
      "          train_loss = 0.672154600794843\n",
      "Epoch 43: valid_loss = 0.6616668122934664\n",
      "          train_loss = 0.6717940743041203\n",
      "Epoch 44: valid_loss = 0.6631813383958862\n",
      "          train_loss = 0.6714385392695772\n",
      "Epoch 45: valid_loss = 0.6622130294889043\n",
      "          train_loss = 0.6717436321841848\n",
      "Epoch 46: valid_loss = 0.6625379543337746\n",
      "          train_loss = 0.6716030033909526\n",
      "Epoch 47: valid_loss = 0.6641095854160401\n",
      "          train_loss = 0.6714340943379588\n",
      "Epoch 48: valid_loss = 0.6641006619964872\n",
      "          train_loss = 0.6712439344872133\n",
      "Epoch 49: valid_loss = 0.6621505692953696\n",
      "          train_loss = 0.6712176520383153\n",
      "Epoch 50: valid_loss = 0.6621917235722067\n",
      "          train_loss = 0.6706984242245871\n",
      "Epoch 51: valid_loss = 0.6632207768039907\n",
      "          train_loss = 0.6710939301711851\n",
      "Epoch 52: valid_loss = 0.6633639368154259\n",
      "          train_loss = 0.6707864286899454\n",
      "Epoch 53: valid_loss = 0.6622296769619102\n",
      "          train_loss = 0.6708104613366088\n",
      "\t\t CV it: 1\n",
      "Epoch 1: valid_loss = 0.7909216179955227\n",
      "          train_loss = 0.9652232657914026\n",
      "Epoch 2: valid_loss = 0.7306267379025486\n",
      "          train_loss = 0.7640867619673326\n",
      "Epoch 3: valid_loss = 0.7101338787641847\n",
      "          train_loss = 0.7250808146828913\n",
      "Epoch 4: valid_loss = 0.7021395451984878\n",
      "          train_loss = 0.7111152559166429\n",
      "Epoch 5: valid_loss = 0.6954529684503641\n",
      "          train_loss = 0.7031459455557516\n",
      "Epoch 6: valid_loss = 0.690924172846196\n",
      "          train_loss = 0.6979737441767143\n",
      "Epoch 7: valid_loss = 0.6878769664370393\n",
      "          train_loss = 0.6938061535969029\n",
      "Epoch 8: valid_loss = 0.6850916447352385\n",
      "          train_loss = 0.6911577500151203\n",
      "Epoch 9: valid_loss = 0.6827480240412463\n",
      "          train_loss = 0.6892396570890054\n",
      "Epoch 10: valid_loss = 0.6852161141312934\n",
      "          train_loss = 0.6874946099917592\n",
      "Epoch 11: valid_loss = 0.6821706532107904\n",
      "          train_loss = 0.6865902713318238\n",
      "Epoch 12: valid_loss = 0.6799164302153157\n",
      "          train_loss = 0.6854755528166376\n",
      "Epoch 13: valid_loss = 0.6787439873882263\n",
      "          train_loss = 0.6847371171315365\n",
      "Epoch 14: valid_loss = 0.67791839035363\n",
      "          train_loss = 0.6836412084315012\n",
      "Epoch 15: valid_loss = 0.6765874011088672\n",
      "          train_loss = 0.6830272323353379\n",
      "Epoch 16: valid_loss = 0.6764578772509288\n",
      "          train_loss = 0.6822667748678212\n",
      "Epoch 17: valid_loss = 0.6752767970547232\n",
      "          train_loss = 0.6814363834298697\n",
      "Epoch 18: valid_loss = 0.6780463112379541\n",
      "          train_loss = 0.6804392498188534\n",
      "Epoch 19: valid_loss = 0.673500838467431\n",
      "          train_loss = 0.6804811632824842\n",
      "Epoch 20: valid_loss = 0.6745271843523154\n",
      "          train_loss = 0.6796012129265815\n",
      "Epoch 21: valid_loss = 0.6718050038739667\n",
      "          train_loss = 0.678898487202998\n",
      "Epoch 22: valid_loss = 0.6696398631216098\n",
      "          train_loss = 0.6780589894566845\n",
      "Epoch 23: valid_loss = 0.6696780053983924\n",
      "          train_loss = 0.677690971595372\n",
      "Epoch 24: valid_loss = 0.6699295605412067\n",
      "          train_loss = 0.6766844424162856\n",
      "Epoch 25: valid_loss = 0.6688585381764325\n",
      "          train_loss = 0.6763627777704628\n",
      "Epoch 26: valid_loss = 0.6676095117034184\n",
      "          train_loss = 0.6754982740607869\n",
      "Epoch 27: valid_loss = 0.6669070451749523\n",
      "          train_loss = 0.6753047840124536\n",
      "Epoch 28: valid_loss = 0.6659404863384584\n",
      "          train_loss = 0.6747936148483965\n",
      "Epoch 29: valid_loss = 0.6666013562863372\n",
      "          train_loss = 0.6744850784309788\n",
      "Epoch 30: valid_loss = 0.6661832253280017\n",
      "          train_loss = 0.6742233444893841\n",
      "Epoch 31: valid_loss = 0.666807696837643\n",
      "          train_loss = 0.6736217077727467\n",
      "Epoch 32: valid_loss = 0.6649585276519853\n",
      "          train_loss = 0.6737544482347119\n",
      "Epoch 33: valid_loss = 0.6661010740897525\n",
      "          train_loss = 0.6733776975442917\n",
      "Epoch 34: valid_loss = 0.6660876520290063\n",
      "          train_loss = 0.6734026144669089\n",
      "Epoch 35: valid_loss = 0.664403969380868\n",
      "          train_loss = 0.672775857640328\n",
      "Epoch 36: valid_loss = 0.6648931326461976\n",
      "          train_loss = 0.672819057973361\n",
      "Epoch 37: valid_loss = 0.6661746261319369\n",
      "          train_loss = 0.6725808120638623\n",
      "Epoch 38: valid_loss = 0.6652947881988491\n",
      "          train_loss = 0.6722182934380162\n",
      "Epoch 39: valid_loss = 0.6658488430216497\n",
      "          train_loss = 0.6725712410832426\n",
      "Epoch 40: valid_loss = 0.6648508684498129\n",
      "          train_loss = 0.6721741764255088\n",
      "Epoch 41: valid_loss = 0.664578886704803\n",
      "          train_loss = 0.6722218234603811\n",
      "Epoch 42: valid_loss = 0.6663695535104899\n",
      "          train_loss = 0.6718903787054541\n",
      "Epoch 43: valid_loss = 0.6654669547192785\n",
      "          train_loss = 0.6715840612301047\n",
      "Epoch 44: valid_loss = 0.6653177767010933\n",
      "          train_loss = 0.6716270843215814\n",
      "Epoch 45: valid_loss = 0.6645358997574567\n",
      "          train_loss = 0.6715086813882012\n",
      "Epoch 46: valid_loss = 0.6628510238009472\n",
      "          train_loss = 0.6714888844350684\n",
      "Epoch 47: valid_loss = 0.6658041084605825\n",
      "          train_loss = 0.6713026836613544\n",
      "Epoch 48: valid_loss = 0.6652000398456552\n",
      "          train_loss = 0.6712354277212875\n",
      "Epoch 49: valid_loss = 0.6644958024262214\n",
      "          train_loss = 0.671275661866038\n",
      "Epoch 50: valid_loss = 0.6632282632631373\n",
      "          train_loss = 0.6711517222606874\n",
      "Epoch 51: valid_loss = 0.6637861114431722\n",
      "          train_loss = 0.6708365475073695\n",
      "Epoch 52: valid_loss = 0.6653480661262491\n",
      "          train_loss = 0.6706521221008603\n",
      "Epoch 53: valid_loss = 0.6668837708608832\n",
      "          train_loss = 0.670639993360138\n",
      "Epoch 54: valid_loss = 0.662946566026589\n",
      "          train_loss = 0.6705510139314779\n",
      "Epoch 55: valid_loss = 0.6628282178010019\n",
      "          train_loss = 0.6701161304364271\n",
      "Epoch 56: valid_loss = 0.6640507660373786\n",
      "          train_loss = 0.670414752654599\n",
      "Epoch 57: valid_loss = 0.6629640635759075\n",
      "          train_loss = 0.6704537715845885\n",
      "Epoch 58: valid_loss = 0.6628364017169279\n",
      "          train_loss = 0.6700155957810716\n",
      "Epoch 59: valid_loss = 0.6621717472529387\n",
      "          train_loss = 0.6700648356574654\n",
      "Epoch 60: valid_loss = 0.6630078421279677\n",
      "          train_loss = 0.6701257759056647\n",
      "Epoch 61: valid_loss = 0.6625843311867852\n",
      "          train_loss = 0.6697536191351648\n",
      "Epoch 62: valid_loss = 0.6622725263121042\n",
      "          train_loss = 0.66969289362325\n",
      "Epoch 63: valid_loss = 0.6627692416874867\n",
      "          train_loss = 0.6699383731734095\n",
      "Epoch 64: valid_loss = 0.6626388109936716\n",
      "          train_loss = 0.6695891207864418\n",
      "Epoch 65: valid_loss = 0.6633355511137815\n",
      "          train_loss = 0.6693987758395672\n",
      "Epoch 66: valid_loss = 0.6619574161591866\n",
      "          train_loss = 0.6691569522987703\n",
      "Epoch 67: valid_loss = 0.6616107393799393\n",
      "          train_loss = 0.6695211634435888\n",
      "Epoch 68: valid_loss = 0.6620425208692857\n",
      "          train_loss = 0.6692790663820404\n",
      "Epoch 69: valid_loss = 0.6637062283860412\n",
      "          train_loss = 0.6692957682482448\n",
      "Epoch 70: valid_loss = 0.6651288468655283\n",
      "          train_loss = 0.6695616962550743\n",
      "Epoch 71: valid_loss = 0.6635373413847762\n",
      "          train_loss = 0.6690849087967293\n",
      "Epoch 72: valid_loss = 0.6640228717257927\n",
      "          train_loss = 0.6690112005527975\n",
      "Epoch 73: valid_loss = 0.6621191431851011\n",
      "          train_loss = 0.6689649044008669\n",
      "Epoch 74: valid_loss = 0.6615075075423221\n",
      "          train_loss = 0.6690106903552125\n",
      "Epoch 75: valid_loss = 0.6614538802943817\n",
      "          train_loss = 0.6690118356091904\n",
      "Epoch 76: valid_loss = 0.6605375662147102\n",
      "          train_loss = 0.6686693868963521\n",
      "Epoch 77: valid_loss = 0.6612114151863799\n",
      "          train_loss = 0.6688862138994277\n",
      "Epoch 78: valid_loss = 0.6622749344579191\n",
      "          train_loss = 0.6688815291130008\n",
      "Epoch 79: valid_loss = 0.6617294626633553\n",
      "          train_loss = 0.668804805356853\n",
      "Epoch 80: valid_loss = 0.6629142483790277\n",
      "          train_loss = 0.66867680199947\n",
      "Epoch 81: valid_loss = 0.6614697219942564\n",
      "          train_loss = 0.6684819222110298\n",
      "Epoch 82: valid_loss = 0.6624537329730855\n",
      "          train_loss = 0.6688531997042538\n",
      "Epoch 83: valid_loss = 0.6612609409512535\n",
      "          train_loss = 0.6680325476299213\n",
      "Epoch 84: valid_loss = 0.6633408190205206\n",
      "          train_loss = 0.6679859543293711\n",
      "Epoch 85: valid_loss = 0.6607439436970425\n",
      "          train_loss = 0.6682992320901829\n",
      "Epoch 86: valid_loss = 0.6618625259441955\n",
      "          train_loss = 0.6681996078308106\n",
      "Epoch 87: valid_loss = 0.6623029231407185\n",
      "          train_loss = 0.6683349482181854\n",
      "\t\t CV it: 2\n",
      "Epoch 1: valid_loss = 0.8052725397689467\n",
      "          train_loss = 0.96261339546208\n",
      "Epoch 2: valid_loss = 0.7456285449301473\n",
      "          train_loss = 0.7609637110429025\n",
      "Epoch 3: valid_loss = 0.7238837239154473\n",
      "          train_loss = 0.7215542259913952\n",
      "Epoch 4: valid_loss = 0.7163378147939313\n",
      "          train_loss = 0.7064769308660087\n",
      "Epoch 5: valid_loss = 0.7089082263164213\n",
      "          train_loss = 0.6985100610286727\n",
      "Epoch 6: valid_loss = 0.7050519856267504\n",
      "          train_loss = 0.6929632002131955\n",
      "Epoch 7: valid_loss = 0.702216445231972\n",
      "          train_loss = 0.6890799098415856\n",
      "Epoch 8: valid_loss = 0.6997032202099882\n",
      "          train_loss = 0.6863557712668489\n",
      "Epoch 9: valid_loss = 0.6977449561564643\n",
      "          train_loss = 0.6843395682757782\n",
      "Epoch 10: valid_loss = 0.6982309261991331\n",
      "          train_loss = 0.6826833866236983\n",
      "Epoch 11: valid_loss = 0.6968780366924396\n",
      "          train_loss = 0.6815473333425066\n",
      "Epoch 12: valid_loss = 0.6985314806393522\n",
      "          train_loss = 0.6807140849200686\n",
      "Epoch 13: valid_loss = 0.695758693829752\n",
      "          train_loss = 0.679483394005645\n",
      "Epoch 14: valid_loss = 0.6956202210838806\n",
      "          train_loss = 0.6790009954855981\n",
      "Epoch 15: valid_loss = 0.6937286311267875\n",
      "          train_loss = 0.6776002484590983\n",
      "Epoch 16: valid_loss = 0.6939603168032521\n",
      "          train_loss = 0.6768139593236883\n",
      "Epoch 17: valid_loss = 0.6947958062122983\n",
      "          train_loss = 0.676490946431075\n",
      "Epoch 18: valid_loss = 0.694334262716966\n",
      "          train_loss = 0.6755833812342614\n",
      "Epoch 19: valid_loss = 0.6918832774875898\n",
      "          train_loss = 0.6751935805430512\n",
      "Epoch 20: valid_loss = 0.6915018218884413\n",
      "          train_loss = 0.6746836152228528\n",
      "Epoch 21: valid_loss = 0.6938534377582026\n",
      "          train_loss = 0.6736518175052033\n",
      "Epoch 22: valid_loss = 0.690728515241259\n",
      "          train_loss = 0.6730443622905277\n",
      "Epoch 23: valid_loss = 0.6900629371587477\n",
      "          train_loss = 0.6724797136027897\n",
      "Epoch 24: valid_loss = 0.6901555924024564\n",
      "          train_loss = 0.6716758290439696\n",
      "Epoch 25: valid_loss = 0.6941650134067299\n",
      "          train_loss = 0.670807430506564\n",
      "Epoch 26: valid_loss = 0.6894137184089044\n",
      "          train_loss = 0.6706318484582433\n",
      "Epoch 27: valid_loss = 0.6871776662542189\n",
      "          train_loss = 0.6700796260775372\n",
      "Epoch 28: valid_loss = 0.6873258405227511\n",
      "          train_loss = 0.6697819994257096\n",
      "Epoch 29: valid_loss = 0.6870035928985242\n",
      "          train_loss = 0.6694166050035446\n",
      "Epoch 30: valid_loss = 0.686655009968826\n",
      "          train_loss = 0.668780190050584\n",
      "Epoch 31: valid_loss = 0.6860610223580097\n",
      "          train_loss = 0.6686544666586938\n",
      "Epoch 32: valid_loss = 0.6856514027096023\n",
      "          train_loss = 0.6686044013241369\n",
      "Epoch 33: valid_loss = 0.6863076094614915\n",
      "          train_loss = 0.6681270293053935\n",
      "Epoch 34: valid_loss = 0.6860139024084867\n",
      "          train_loss = 0.6679318409688473\n",
      "Epoch 35: valid_loss = 0.6866550433592454\n",
      "          train_loss = 0.6679073462692497\n",
      "Epoch 36: valid_loss = 0.6851204839550896\n",
      "          train_loss = 0.6678156772179408\n",
      "Epoch 37: valid_loss = 0.687661633603167\n",
      "          train_loss = 0.6675626141752378\n",
      "Epoch 38: valid_loss = 0.6849152161403272\n",
      "          train_loss = 0.6673813084367924\n",
      "Epoch 39: valid_loss = 0.6841248167384911\n",
      "          train_loss = 0.6672134259671628\n",
      "Epoch 40: valid_loss = 0.6856027407734616\n",
      "          train_loss = 0.6672843092412986\n",
      "Epoch 41: valid_loss = 0.6856259014667434\n",
      "          train_loss = 0.6670822813860007\n",
      "Epoch 42: valid_loss = 0.6842385943910985\n",
      "          train_loss = 0.6666168442809521\n",
      "Epoch 43: valid_loss = 0.6838533153976816\n",
      "          train_loss = 0.6666100643651113\n",
      "Epoch 44: valid_loss = 0.6845015400621401\n",
      "          train_loss = 0.6667706921121188\n",
      "Epoch 45: valid_loss = 0.686347507820596\n",
      "          train_loss = 0.6665359058228875\n",
      "Epoch 46: valid_loss = 0.6850756391652668\n",
      "          train_loss = 0.6662649329367124\n",
      "Epoch 47: valid_loss = 0.6845422950273068\n",
      "          train_loss = 0.666292810039699\n",
      "Epoch 48: valid_loss = 0.682570937866209\n",
      "          train_loss = 0.6662782490364559\n",
      "Epoch 49: valid_loss = 0.6843674413699786\n",
      "          train_loss = 0.6659656319721843\n",
      "Epoch 50: valid_loss = 0.6836736318191866\n",
      "          train_loss = 0.6660175645924769\n",
      "Epoch 51: valid_loss = 0.6845333949754652\n",
      "          train_loss = 0.6659543959387797\n",
      "Epoch 52: valid_loss = 0.6832270426852801\n",
      "          train_loss = 0.6656080219566615\n",
      "Epoch 53: valid_loss = 0.6835716765904633\n",
      "          train_loss = 0.6657167566082641\n",
      "Epoch 54: valid_loss = 0.6827722915407592\n",
      "          train_loss = 0.6657787155033422\n",
      "Epoch 55: valid_loss = 0.6829207311212876\n",
      "          train_loss = 0.6656986652104059\n",
      "Epoch 56: valid_loss = 0.684421285555083\n",
      "          train_loss = 0.6657374156440162\n",
      "Epoch 57: valid_loss = 0.6824899146866331\n",
      "          train_loss = 0.6653991313166715\n",
      "Epoch 58: valid_loss = 0.6814950993377774\n",
      "          train_loss = 0.6654556192908492\n",
      "Epoch 59: valid_loss = 0.6820533977386566\n",
      "          train_loss = 0.6652712792813122\n",
      "Epoch 60: valid_loss = 0.6828385116774975\n",
      "          train_loss = 0.6650528557338401\n",
      "Epoch 61: valid_loss = 0.6840585620985059\n",
      "          train_loss = 0.665049124444798\n",
      "Epoch 62: valid_loss = 0.6812877648813593\n",
      "          train_loss = 0.6648013669749955\n",
      "Epoch 63: valid_loss = 0.6833718497900481\n",
      "          train_loss = 0.6649040723014977\n",
      "Epoch 64: valid_loss = 0.6807163272638819\n",
      "          train_loss = 0.6651201271797553\n",
      "Epoch 65: valid_loss = 0.682911326160602\n",
      "          train_loss = 0.6647234414975935\n",
      "Epoch 66: valid_loss = 0.6838814273727525\n",
      "          train_loss = 0.6648237473587897\n",
      "Epoch 67: valid_loss = 0.6815759812798118\n",
      "          train_loss = 0.6647103014374691\n",
      "Epoch 68: valid_loss = 0.6811294033752479\n",
      "          train_loss = 0.6650438885336171\n",
      "Epoch 69: valid_loss = 0.6820571358578613\n",
      "          train_loss = 0.664454397432715\n",
      "Epoch 70: valid_loss = 0.6822936690205137\n",
      "          train_loss = 0.6643398699842372\n",
      "Epoch 71: valid_loss = 0.6813810546329934\n",
      "          train_loss = 0.664215735127004\n",
      "Epoch 72: valid_loss = 0.6815193709222711\n",
      "          train_loss = 0.6648451153521572\n",
      "Epoch 73: valid_loss = 0.6823632085419166\n",
      "          train_loss = 0.6646906525015528\n",
      "Epoch 74: valid_loss = 0.6819137727054758\n",
      "          train_loss = 0.6643667545092518\n",
      "Epoch 75: valid_loss = 0.6819976096213565\n",
      "          train_loss = 0.6644798046360204\n",
      "\t\t CV it: 3\n",
      "Epoch 1: valid_loss = 0.806343185190089\n",
      "          train_loss = 0.9585174058053467\n",
      "Epoch 2: valid_loss = 0.7385026881975522\n",
      "          train_loss = 0.7613838855189047\n",
      "Epoch 3: valid_loss = 0.7156255867688405\n",
      "          train_loss = 0.7225231216870351\n",
      "Epoch 4: valid_loss = 0.7034812285802108\n",
      "          train_loss = 0.7091170722494672\n",
      "Epoch 5: valid_loss = 0.6963927758212101\n",
      "          train_loss = 0.7008057535837704\n",
      "Epoch 6: valid_loss = 0.6926695988665839\n",
      "          train_loss = 0.6955441969122538\n",
      "Epoch 7: valid_loss = 0.6896914888914139\n",
      "          train_loss = 0.6915131493723994\n",
      "Epoch 8: valid_loss = 0.6888045031022336\n",
      "          train_loss = 0.6889580620666379\n",
      "Epoch 9: valid_loss = 0.6897896425063127\n",
      "          train_loss = 0.6869202795273042\n",
      "Epoch 10: valid_loss = 0.687847211578926\n",
      "          train_loss = 0.6854929055980156\n",
      "Epoch 11: valid_loss = 0.687038765094258\n",
      "          train_loss = 0.6842062042568064\n",
      "Epoch 12: valid_loss = 0.6841169471052035\n",
      "          train_loss = 0.6830773966935457\n",
      "Epoch 13: valid_loss = 0.684374668077699\n",
      "          train_loss = 0.682086710355748\n",
      "Epoch 14: valid_loss = 0.6859117546699539\n",
      "          train_loss = 0.6811382003351198\n",
      "Epoch 15: valid_loss = 0.683097792089879\n",
      "          train_loss = 0.6805788013160871\n",
      "Epoch 16: valid_loss = 0.6828590654256734\n",
      "          train_loss = 0.679736034105163\n",
      "Epoch 17: valid_loss = 0.6815206061899952\n",
      "          train_loss = 0.6787919425400145\n",
      "Epoch 18: valid_loss = 0.6833657392633388\n",
      "          train_loss = 0.6779551004013623\n",
      "Epoch 19: valid_loss = 0.6807801425922672\n",
      "          train_loss = 0.6775161760595056\n",
      "Epoch 20: valid_loss = 0.6817395991918427\n",
      "          train_loss = 0.6764451211154079\n",
      "Epoch 21: valid_loss = 0.6826986180432676\n",
      "          train_loss = 0.6758032020954303\n",
      "Epoch 22: valid_loss = 0.6798540646090381\n",
      "          train_loss = 0.6747780436468979\n",
      "Epoch 23: valid_loss = 0.6797008351117895\n",
      "          train_loss = 0.6744023064257101\n",
      "Epoch 24: valid_loss = 0.6792878879841172\n",
      "          train_loss = 0.6740953761850369\n",
      "Epoch 25: valid_loss = 0.6786662319429883\n",
      "          train_loss = 0.6732461907304411\n",
      "Epoch 26: valid_loss = 0.6784593060299132\n",
      "          train_loss = 0.6726519307281377\n",
      "Epoch 27: valid_loss = 0.6799847954839304\n",
      "          train_loss = 0.6721490748045136\n",
      "Epoch 28: valid_loss = 0.6801103627392139\n",
      "          train_loss = 0.671730801959174\n",
      "Epoch 29: valid_loss = 0.6803970804592768\n",
      "          train_loss = 0.6716915567054313\n",
      "Epoch 30: valid_loss = 0.6786071414477933\n",
      "          train_loss = 0.6715164675614527\n",
      "Epoch 31: valid_loss = 0.6784977514981081\n",
      "          train_loss = 0.6709245583592516\n",
      "Epoch 32: valid_loss = 0.6782943252529494\n",
      "          train_loss = 0.6705476397567737\n",
      "Epoch 33: valid_loss = 0.6780855045520525\n",
      "          train_loss = 0.6704213751130305\n",
      "Epoch 34: valid_loss = 0.6781227871993442\n",
      "          train_loss = 0.6702534970763906\n",
      "Epoch 35: valid_loss = 0.6785716586383677\n",
      "          train_loss = 0.670071163997313\n",
      "Epoch 36: valid_loss = 0.6784309451495313\n",
      "          train_loss = 0.6699514630546672\n",
      "Epoch 37: valid_loss = 0.6814743739080993\n",
      "          train_loss = 0.6693103353942177\n",
      "Epoch 38: valid_loss = 0.6771399812249429\n",
      "          train_loss = 0.6695411038933718\n",
      "Epoch 39: valid_loss = 0.6781416332503127\n",
      "          train_loss = 0.6693148021705212\n",
      "Epoch 40: valid_loss = 0.6776674671640783\n",
      "          train_loss = 0.6694914295600952\n",
      "Epoch 41: valid_loss = 0.6766497411112344\n",
      "          train_loss = 0.6692038575037006\n",
      "Epoch 42: valid_loss = 0.6776754318299468\n",
      "          train_loss = 0.6689645409250414\n",
      "Epoch 43: valid_loss = 0.678243217535578\n",
      "          train_loss = 0.6690236165318738\n",
      "Epoch 44: valid_loss = 0.6772021453476542\n",
      "          train_loss = 0.6687805136463995\n",
      "Epoch 45: valid_loss = 0.6765821293986048\n",
      "          train_loss = 0.6683782971755342\n",
      "Epoch 46: valid_loss = 0.6768121776553399\n",
      "          train_loss = 0.6686583874831931\n",
      "Epoch 47: valid_loss = 0.6768981832758003\n",
      "          train_loss = 0.6682210460995355\n",
      "Epoch 48: valid_loss = 0.679089782335436\n",
      "          train_loss = 0.6684042678268439\n",
      "Epoch 49: valid_loss = 0.6774182839375975\n",
      "          train_loss = 0.6679199662447847\n",
      "Epoch 50: valid_loss = 0.6766306071878225\n",
      "          train_loss = 0.6680945591802178\n",
      "Epoch 51: valid_loss = 0.6761830233564124\n",
      "          train_loss = 0.6681556676224093\n",
      "Epoch 52: valid_loss = 0.6838777895522533\n",
      "          train_loss = 0.6679172431519897\n",
      "Epoch 53: valid_loss = 0.6777081090149143\n",
      "          train_loss = 0.6677364095797004\n",
      "Epoch 54: valid_loss = 0.6762703743395182\n",
      "          train_loss = 0.6678537114633673\n",
      "Epoch 55: valid_loss = 0.6773952353752806\n",
      "          train_loss = 0.6675966614471361\n",
      "Epoch 56: valid_loss = 0.6771578837258644\n",
      "          train_loss = 0.6678553910044449\n",
      "Epoch 57: valid_loss = 0.6748116613478236\n",
      "          train_loss = 0.6672423088884498\n",
      "Epoch 58: valid_loss = 0.6769900312915875\n",
      "          train_loss = 0.6669728390100949\n",
      "Epoch 59: valid_loss = 0.6758886842759039\n",
      "          train_loss = 0.6674162757894564\n",
      "Epoch 60: valid_loss = 0.6760736221669352\n",
      "          train_loss = 0.667237761107354\n",
      "Epoch 61: valid_loss = 0.6761070416203231\n",
      "          train_loss = 0.6672880711991034\n",
      "Epoch 62: valid_loss = 0.6764369661805336\n",
      "          train_loss = 0.6667910722054362\n",
      "Epoch 63: valid_loss = 0.6778027561590656\n",
      "          train_loss = 0.6668101005829754\n",
      "Epoch 64: valid_loss = 0.6756302221460656\n",
      "          train_loss = 0.6667220413176833\n",
      "Epoch 65: valid_loss = 0.6770511491799812\n",
      "          train_loss = 0.6667917184015992\n",
      "Epoch 66: valid_loss = 0.6766504401130717\n",
      "          train_loss = 0.666485492495657\n",
      "Epoch 67: valid_loss = 0.6807891486780847\n",
      "          train_loss = 0.6669595542731888\n",
      "Epoch 68: valid_loss = 0.6811241168612213\n",
      "          train_loss = 0.6664118451650431\n",
      "\t\t CV it: 4\n",
      "Epoch 1: valid_loss = 0.8047099074765668\n",
      "          train_loss = 0.9634838544659207\n",
      "Epoch 2: valid_loss = 0.7448371105813624\n",
      "          train_loss = 0.7605329376354715\n",
      "Epoch 3: valid_loss = 0.7286912359697625\n",
      "          train_loss = 0.7191826796309809\n",
      "Epoch 4: valid_loss = 0.7209502336734473\n",
      "          train_loss = 0.7047617033272731\n",
      "Epoch 5: valid_loss = 0.7155018549957182\n",
      "          train_loss = 0.6974435607161308\n",
      "Epoch 6: valid_loss = 0.7111075507184369\n",
      "          train_loss = 0.6923252519807215\n",
      "Epoch 7: valid_loss = 0.7074591235113508\n",
      "          train_loss = 0.6890901778360777\n",
      "Epoch 8: valid_loss = 0.7036684685282536\n",
      "          train_loss = 0.6867169922136405\n",
      "Epoch 9: valid_loss = 0.7014976601599815\n",
      "          train_loss = 0.6846993488324999\n",
      "Epoch 10: valid_loss = 0.6999336457075189\n",
      "          train_loss = 0.6831187549516576\n",
      "Epoch 11: valid_loss = 0.7006530828204927\n",
      "          train_loss = 0.6818869829264503\n",
      "Epoch 12: valid_loss = 0.6975218567028146\n",
      "          train_loss = 0.6811118104827992\n",
      "Epoch 13: valid_loss = 0.6964059364654084\n",
      "          train_loss = 0.680399653179087\n",
      "Epoch 14: valid_loss = 0.6967792723533253\n",
      "          train_loss = 0.6794208607894848\n",
      "Epoch 15: valid_loss = 0.6984877303171615\n",
      "          train_loss = 0.6788030254296341\n",
      "Epoch 16: valid_loss = 0.6940269924295907\n",
      "          train_loss = 0.677962474340156\n",
      "Epoch 17: valid_loss = 0.6946711882024006\n",
      "          train_loss = 0.677305035971764\n",
      "Epoch 18: valid_loss = 0.6940740596250098\n",
      "          train_loss = 0.6769441512049619\n",
      "Epoch 19: valid_loss = 0.692755687800484\n",
      "          train_loss = 0.6759752206925651\n",
      "Epoch 20: valid_loss = 0.6917425720759923\n",
      "          train_loss = 0.675771760109573\n",
      "Epoch 21: valid_loss = 0.6909896617228762\n",
      "          train_loss = 0.6749721180298787\n",
      "Epoch 22: valid_loss = 0.6905436539592528\n",
      "          train_loss = 0.6742100532059698\n",
      "Epoch 23: valid_loss = 0.6909534710139691\n",
      "          train_loss = 0.6737235139933658\n",
      "Epoch 24: valid_loss = 0.6883764856738949\n",
      "          train_loss = 0.6730757996194198\n",
      "Epoch 25: valid_loss = 0.6872069241092856\n",
      "          train_loss = 0.6728214625459288\n",
      "Epoch 26: valid_loss = 0.6868006727729072\n",
      "          train_loss = 0.6719638835434085\n",
      "Epoch 27: valid_loss = 0.6865248752166547\n",
      "          train_loss = 0.6715481083796455\n",
      "Epoch 28: valid_loss = 0.6858975201959925\n",
      "          train_loss = 0.6706235476857941\n",
      "Epoch 29: valid_loss = 0.6848159854812292\n",
      "          train_loss = 0.6704170756865846\n",
      "Epoch 30: valid_loss = 0.6857660575227491\n",
      "          train_loss = 0.6700576532211737\n",
      "Epoch 31: valid_loss = 0.685828187355735\n",
      "          train_loss = 0.669808891762808\n",
      "Epoch 32: valid_loss = 0.6837019675528254\n",
      "          train_loss = 0.6699576726549094\n",
      "Epoch 33: valid_loss = 0.6839843258563408\n",
      "          train_loss = 0.6693209682148584\n",
      "Epoch 34: valid_loss = 0.6820387874073687\n",
      "          train_loss = 0.6687078162855179\n",
      "Epoch 35: valid_loss = 0.6832682383186403\n",
      "          train_loss = 0.6688975470386893\n",
      "Epoch 36: valid_loss = 0.682974713668479\n",
      "          train_loss = 0.6685509933938969\n",
      "Epoch 37: valid_loss = 0.6830175211067657\n",
      "          train_loss = 0.6686961984848185\n",
      "Epoch 38: valid_loss = 0.6826712004263712\n",
      "          train_loss = 0.6681247855789987\n",
      "Epoch 39: valid_loss = 0.683388950975815\n",
      "          train_loss = 0.668229718202764\n",
      "Epoch 40: valid_loss = 0.6825863333001735\n",
      "          train_loss = 0.6679622770503649\n",
      "Epoch 41: valid_loss = 0.68218447070903\n",
      "          train_loss = 0.6677909110235308\n",
      "Epoch 42: valid_loss = 0.6820764758499844\n",
      "          train_loss = 0.6675135060203975\n",
      "Epoch 43: valid_loss = 0.6817767803475376\n",
      "          train_loss = 0.6673765584850098\n",
      "Epoch 44: valid_loss = 0.6824906227712055\n",
      "          train_loss = 0.667420411228778\n",
      "Epoch 45: valid_loss = 0.6813426821993956\n",
      "          train_loss = 0.6671646340042015\n",
      "Epoch 46: valid_loss = 0.6826900981231572\n",
      "          train_loss = 0.6672640607413547\n",
      "Epoch 47: valid_loss = 0.6824640781537424\n",
      "          train_loss = 0.667133615457418\n",
      "Epoch 48: valid_loss = 0.6822137687965376\n",
      "          train_loss = 0.6668590457762928\n",
      "Epoch 49: valid_loss = 0.682186521737034\n",
      "          train_loss = 0.6669330866104035\n",
      "Epoch 50: valid_loss = 0.6828188860140885\n",
      "          train_loss = 0.6668227146608957\n",
      "Epoch 51: valid_loss = 0.6812948777322415\n",
      "          train_loss = 0.6666109123826749\n",
      "Epoch 52: valid_loss = 0.681195428697272\n",
      "          train_loss = 0.6665148354406668\n",
      "Epoch 53: valid_loss = 0.6817324638130615\n",
      "          train_loss = 0.6666257584907341\n",
      "Epoch 54: valid_loss = 0.6809067914071746\n",
      "          train_loss = 0.6664500292843738\n",
      "Epoch 55: valid_loss = 0.6807396697622163\n",
      "          train_loss = 0.6663225940518849\n",
      "Epoch 56: valid_loss = 0.6827447709917988\n",
      "          train_loss = 0.6661078197521354\n",
      "Epoch 57: valid_loss = 0.6816794786841005\n",
      "          train_loss = 0.6660864182316714\n",
      "Epoch 58: valid_loss = 0.680888589289642\n",
      "          train_loss = 0.6658062583538177\n",
      "Epoch 59: valid_loss = 0.6811565822169123\n",
      "          train_loss = 0.6659003568664444\n",
      "Epoch 60: valid_loss = 0.6829748335421911\n",
      "          train_loss = 0.6656564445229823\n",
      "Epoch 61: valid_loss = 0.6831336943553861\n",
      "          train_loss = 0.6658639360254773\n",
      "Epoch 62: valid_loss = 0.6828678236675046\n",
      "          train_loss = 0.6656849245157821\n",
      "Epoch 63: valid_loss = 0.681910302383618\n",
      "          train_loss = 0.6653343676533305\n",
      "Epoch 64: valid_loss = 0.6812478030534246\n",
      "          train_loss = 0.6652728217634427\n",
      "Epoch 65: valid_loss = 0.6803517105942959\n",
      "          train_loss = 0.6655116679377655\n",
      "Epoch 66: valid_loss = 0.6825296935144205\n",
      "          train_loss = 0.6652261397092508\n",
      "Epoch 67: valid_loss = 0.6818832332106529\n",
      "          train_loss = 0.6650237051149779\n",
      "Epoch 68: valid_loss = 0.6823088905851395\n",
      "          train_loss = 0.6649163007376007\n",
      "Epoch 69: valid_loss = 0.682919846489698\n",
      "          train_loss = 0.6649681122512106\n",
      "Epoch 70: valid_loss = 0.6813763001889565\n",
      "          train_loss = 0.6647140327417534\n",
      "Epoch 71: valid_loss = 0.6820866178879598\n",
      "          train_loss = 0.6647837807249123\n",
      "Epoch 72: valid_loss = 0.6817157770796037\n",
      "          train_loss = 0.6647460516870856\n",
      "Epoch 73: valid_loss = 0.6806303629824851\n",
      "          train_loss = 0.664697250912226\n",
      "Epoch 74: valid_loss = 0.6829832543742886\n",
      "          train_loss = 0.6647138403026586\n",
      "Epoch 75: valid_loss = 0.6796702109349405\n",
      "          train_loss = 0.6643474672040789\n",
      "Epoch 76: valid_loss = 0.6809067298073871\n",
      "          train_loss = 0.6641841973501671\n",
      "Epoch 77: valid_loss = 0.6801259273102032\n",
      "          train_loss = 0.6644315162753744\n",
      "Epoch 78: valid_loss = 0.6816239199994021\n",
      "          train_loss = 0.6641583482800308\n",
      "Epoch 79: valid_loss = 0.6802697742348348\n",
      "          train_loss = 0.6643864239885726\n",
      "Epoch 80: valid_loss = 0.6812672209852131\n",
      "          train_loss = 0.6640175347705664\n",
      "Epoch 81: valid_loss = 0.6800061218002891\n",
      "          train_loss = 0.6640489397392472\n",
      "Epoch 82: valid_loss = 0.6814682442877836\n",
      "          train_loss = 0.6637181313659072\n",
      "Epoch 83: valid_loss = 0.6829790445018217\n",
      "          train_loss = 0.6640052644097997\n",
      "Epoch 84: valid_loss = 0.6806363286787241\n",
      "          train_loss = 0.664122027302678\n",
      "Epoch 85: valid_loss = 0.6797847456476781\n",
      "          train_loss = 0.6640532935483924\n",
      "Epoch 86: valid_loss = 0.6797087303246465\n",
      "          train_loss = 0.6639515537745105\n",
      "\t    + Elapsed: 588.0 seconds\n"
     ]
    }
   ],
   "source": [
    "## Execute experiments\n",
    "\n",
    "## Initialize dictionaries to store partial results\n",
    "# Load the previous experiment data (deserialize)\n",
    "try:\n",
    "    with open(partial_results_dir + '/Experiment_4_CV_scores.pickle', 'rb') as handle:\n",
    "        Experiment_4_CV_scores = pickle.load(handle)\n",
    "except:\n",
    "    Experiment_4_CV_scores = {}\n",
    "try:\n",
    "    with open(partial_results_dir + '/Experiment_4_test_scores.pickle', 'rb') as handle:\n",
    "        Experiment_4_test_scores = pickle.load(handle)\n",
    "except:\n",
    "    Experiment_4_test_scores = {}\n",
    "\n",
    "n_epochs = 0\n",
    "\n",
    "for dataset_id, dataset in datasets.items():\n",
    "    dataset_name = dataset[\"name\"]\n",
    "    print(\"\\n--- {} (ID: {})\".format(dataset_name, dataset_id))\n",
    "\n",
    "    # Load the data and the hyperparameters\n",
    "    X, y, final_test_X, final_test_y, alts, groups, hyperparameters = load_data(dataset_id, dataset)\n",
    "\n",
    "    # Obtain datasets for K-Fold cross validation (the same fold splits are used across all the iterations for all models)\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    crossval_pickle_file = data_dir+dataset_id+\"_crossval.pickle\"\n",
    "    try:\n",
    "        train_indices, test_indices = pickle.load(open(crossval_pickle_file, \"rb\"))\n",
    "        if reset_crossval_indices == 1: # Reset the indices\n",
    "            raise FileNotFoundError\n",
    "    except (OSError, IOError) as e:\n",
    "        print(\"Recomputing Cross-val indices...\")\n",
    "        for (train_index, test_index) in stratified_group_k_fold(X, y, groups, k=CV, seed=1):\n",
    "            train_indices.append(train_index)\n",
    "            test_indices.append(test_index)\n",
    "        pickle.dump([train_indices, test_indices], open(crossval_pickle_file, \"wb\"))\n",
    "\n",
    "\n",
    "    # Get results for the selected classifier\n",
    "    for classifier in model_type_to_class.keys():\n",
    "        print(\"\\n\\t--- {}\".format(classifier))\n",
    "        sys.stdout.flush()\n",
    "        it_time_init = time.perf_counter()\n",
    "\n",
    "        # Create dictionary to store the results\n",
    "        if not classifier in Experiment_4_CV_scores.keys():\n",
    "            Experiment_4_CV_scores[classifier] = {}\n",
    "        if not classifier in Experiment_4_test_scores.keys():\n",
    "            Experiment_4_test_scores[classifier] = {}\n",
    "\n",
    "        if recompute_Experiment_4==True or not (dataset_name in Experiment_4_CV_scores[classifier].keys()) or not (dataset_name in Experiment_4_test_scores[classifier].keys()):\n",
    "            # Create dictionary to store the results\n",
    "            Experiment_4_CV_scores[classifier][dataset_name] = {}\n",
    "            Experiment_4_CV_scores[classifier][dataset_name]['Accuracy'] = []\n",
    "            Experiment_4_CV_scores[classifier][dataset_name]['F1'] = []\n",
    "            Experiment_4_CV_scores[classifier][dataset_name]['Recall'] = []\n",
    "            Experiment_4_CV_scores[classifier][dataset_name]['GMPCA'] = []\n",
    "            Experiment_4_CV_scores[classifier][dataset_name]['Estimation time'] = []\n",
    "            Experiment_4_test_scores[classifier][dataset_name] = {}\n",
    "\n",
    "            ## Applying k-Fold Cross Validation over training set\n",
    "            for iteration in range(0, len(train_indices)):\n",
    "                print(\"\\t\\t CV it: {}\".format(iteration))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "                # Create the classifier\n",
    "                if classifier == \"ResLogit\":\n",
    "                    params = create_classifier(classifier, hyperparameters, dataset, X, y, for_CV=True)\n",
    "                else:\n",
    "                    clf = create_classifier(classifier, hyperparameters, dataset, X, y, for_CV=True)\n",
    "\n",
    "                # Obtain training and testing data for this iteration (split of de k-Fold)\n",
    "                X_train, X_test = X.loc[train_indices[iteration]], X.loc[test_indices[iteration]]\n",
    "                y_train, y_test = y.loc[train_indices[iteration]], y.loc[test_indices[iteration]]\n",
    "\n",
    "                # Scale the data\n",
    "                scaler = StandardScaler()\n",
    "                scaler.fit(X_train[dataset[\"scaled_fetures\"]])\n",
    "                X_train.loc[:, dataset[\"scaled_fetures\"]] = scaler.transform(X_train[dataset[\"scaled_fetures\"]])\n",
    "                X_test.loc[:, dataset[\"scaled_fetures\"]] = scaler.transform(X_test[dataset[\"scaled_fetures\"]])\n",
    "\n",
    "                # Balance dataset\n",
    "                #X_train, y_train = balance(X_train, y_train, X_train.shape[0], len(dataset[\"alt_names\"]))\n",
    "                \n",
    "                time_ini = time.perf_counter()\n",
    "                if classifier == \"ResLogit\":\n",
    "                    X_train_res = alt_spec_data(X_train)\n",
    "                    X_test_res = alt_spec_data(X_test)\n",
    "                    \n",
    "                    clf = ResLogit(X_train_res, y_train, X_train_res.shape[1], params[\"output_dim\"], n_layers=params['depth'], batch_size=params['batch_size'], epochs=params['epochs'], device=torch.device('cpu'))\n",
    "                    #clf = ResLogit(X_train, y_train, params[\"input_dim\"], params[\"output_dim\"], n_layers=4, batch_size=264, epochs=params['epochs'], device=torch.device('cuda'))\n",
    "                    _, epochs, _ = clf.train(X_train_res, y_train, X_test_res, y_test, valid_iter=1)\n",
    "                    proba = clf.predict_validate(X_test_res)\n",
    "                    n_epochs += epochs\n",
    "                    \n",
    "                    #proba = np.where(proba < 1e-5, 1e-5, proba)\n",
    "                    y_score = np.argmax(proba, axis=1)\n",
    "                else:\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    y_score = clf.predict(X_test)\n",
    "                    proba = clf.predict_proba(X_test)\n",
    "                elapsed_time = time.perf_counter() - time_ini\n",
    "\n",
    "                \n",
    "\n",
    "                # Compute the accuracy results\n",
    "                Experiment_4_CV_scores[classifier][dataset_name]['Accuracy'] = np.append(Experiment_4_CV_scores[classifier][dataset_name]['Accuracy'], accuracy_score(y_test, y_score)*100)\n",
    "                Experiment_4_CV_scores[classifier][dataset_name]['F1'] = np.append(Experiment_4_CV_scores[classifier][dataset_name]['F1'], f1_score(y_test, y_score, average=average_tech)*100)\n",
    "                Experiment_4_CV_scores[classifier][dataset_name]['Recall'] = np.append(Experiment_4_CV_scores[classifier][dataset_name]['Recall'], recall_score(y_test, y_score, average=average_tech)*100)\n",
    "                Experiment_4_CV_scores[classifier][dataset_name]['GMPCA'] = np.append(Experiment_4_CV_scores[classifier][dataset_name]['GMPCA'], GMPCA(proba, y_test.values)*100)\n",
    "                Experiment_4_CV_scores[classifier][dataset_name]['Estimation time'] = np.append(Experiment_4_CV_scores[classifier][dataset_name]['Estimation time'], elapsed_time)\n",
    "\n",
    "                del clf\n",
    "                gc.collect()\n",
    "\n",
    "            ## Out-of-sample results\n",
    "            # Create the classifier\n",
    "            if classifier == \"ResLogit\":\n",
    "                params = create_classifier(classifier, hyperparameters, dataset, X, y)\n",
    "                n_epochs = n_epochs // CV\n",
    "            else:\n",
    "                clf = create_classifier(classifier, hyperparameters, dataset, X, y)\n",
    "            fitted = True\n",
    "\n",
    "            # Scale the data\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X[dataset[\"scaled_fetures\"]])\n",
    "            X_scaled = X.copy()\n",
    "            final_test_X_scaled = final_test_X.copy()\n",
    "            X_scaled.loc[:, dataset[\"scaled_fetures\"]] = scaler.transform(X_scaled[dataset[\"scaled_fetures\"]])\n",
    "            final_test_X_scaled.loc[:, dataset[\"scaled_fetures\"]] = scaler.transform(final_test_X_scaled[dataset[\"scaled_fetures\"]])\n",
    "\n",
    "            # Balance dataset\n",
    "            #X_scaled_balanced, y_balanced = balance(X_scaled, y, X_scaled.shape[0], len(dataset[\"alt_names\"]))\n",
    "\n",
    "            # Fit the classifier on training set\n",
    "            time_ini = time.perf_counter()\n",
    "            if classifier == \"ResLogit\":\n",
    "                X_scaled_res = alt_spec_data(X_scaled)\n",
    "                final_test_X_scaled_res = alt_spec_data(final_test_X_scaled)\n",
    "                clf = ResLogit(X_scaled_res, y, X_scaled_res.shape[1], params[\"output_dim\"], n_layers=params['depth'], batch_size=params['batch_size'], epochs=n_epochs, device=torch.device('cpu'))\n",
    "                _, _, _ = clf.train(X_scaled_res, y, None, None)\n",
    "                proba = clf.predict_validate(final_test_X_scaled_res)\n",
    "                #proba = np.where(proba < 1e-5, 1e-5, proba)\n",
    "                y_score = np.argmax(proba, axis=1)\n",
    "            else:\n",
    "                clf.fit(X_scaled, y)\n",
    "                y_score = clf.predict(final_test_X_scaled)\n",
    "                proba = clf.predict_proba(final_test_X_scaled)\n",
    "\n",
    "            elapsed_time = time.perf_counter() - time_ini\n",
    "            fitted = True\n",
    "            \n",
    "            \n",
    "            # Compute the accuracy results\n",
    "            Experiment_4_test_scores[classifier][dataset_name]['Accuracy'] = accuracy_score(final_test_y, y_score)*100\n",
    "            Experiment_4_test_scores[classifier][dataset_name]['F1'] = f1_score(final_test_y, y_score, average=average_tech)*100\n",
    "            Experiment_4_test_scores[classifier][dataset_name]['Recall'] = recall_score(final_test_y, y_score, average=average_tech)*100\n",
    "            Experiment_4_test_scores[classifier][dataset_name]['GMPCA'] = GMPCA(proba, final_test_y.values)*100\n",
    "            Experiment_4_test_scores[classifier][dataset_name]['Estimation time'] = elapsed_time\n",
    "\n",
    "            # ## Market shares\n",
    "            # Experiment_4_CV_scores[classifier][dataset_name]['Market_shares'] = np.round(np.sum(clf.predict_proba(X_scaled), axis=0)/X_scaled.shape[0] * 100, 3)\n",
    "            # Experiment_4_test_scores[classifier][dataset_name]['Market_shares'] = np.round(np.sum(clf.predict_proba(final_test_X_scaled), axis=0)/final_test_X_scaled.shape[0] * 100, 3)\n",
    "            \n",
    "            # ## WTP\n",
    "            # Experiment_4_CV_scores[classifier][dataset_name][\"WTP_history\"] = None\n",
    "            # Experiment_4_test_scores[classifier][dataset_name][\"WTP_history\"] = None\n",
    "            # if dataset[\"WTP\"] is not None:\n",
    "            #     Experiment_4_CV_scores[classifier][dataset_name][\"WTP_history\"] = {}\n",
    "            #     Experiment_4_CV_scores[classifier][dataset_name][\"n_WTP_nan\"] = 0\n",
    "            #     Experiment_4_CV_scores[classifier][dataset_name][\"n_WTP_inf\"] = 0\n",
    "            #     Experiment_4_test_scores[classifier][dataset_name][\"WTP_history\"] = {}\n",
    "            #     Experiment_4_test_scores[classifier][dataset_name][\"n_WTP_nan\"] = 0\n",
    "            #     Experiment_4_test_scores[classifier][dataset_name][\"n_WTP_inf\"] = 0\n",
    "\n",
    "            #     for alt in dataset[\"WTP\"].keys():\n",
    "            #         v1_name, v2_name, d_1, d_2 = dataset[\"WTP\"][alt]\n",
    "\n",
    "            #         # WTP over training set \n",
    "            #         filtered_WTP, n_WTP_nan, n_WTP_inf = compute_WTP(clf, dataset, X, v1_name, v2_name, d_1, d_2, scaler)\n",
    "            #         Experiment_4_CV_scores[classifier][dataset_name][\"n_WTP_nan\"] += n_WTP_nan\n",
    "            #         Experiment_4_CV_scores[classifier][dataset_name][\"n_WTP_inf\"] += n_WTP_inf\n",
    "            #         Experiment_4_CV_scores[classifier][dataset_name][\"WTP_history\"][dataset[\"alt_names\"][alt]] = filtered_WTP\n",
    "\n",
    "            #         # WTP over test set \n",
    "            #         filtered_WTP, n_WTP_nan, n_WTP_inf = compute_WTP(clf, dataset, final_test_X, v1_name, v2_name, d_1, d_2, scaler)\n",
    "            #         Experiment_4_test_scores[classifier][dataset_name][\"n_WTP_nan\"] += n_WTP_nan\n",
    "            #         Experiment_4_test_scores[classifier][dataset_name][\"n_WTP_inf\"] += n_WTP_inf\n",
    "            #         Experiment_4_test_scores[classifier][dataset_name][\"WTP_history\"][dataset[\"alt_names\"][alt]] = filtered_WTP\n",
    "\n",
    "            del clf \n",
    "            gc.collect()\n",
    "\n",
    "        # Store the partial experiment data (serialize)\n",
    "        with open(partial_results_dir + 'Experiment_4_CV_scores.pickle', 'wb') as handle:\n",
    "            pickle.dump(Experiment_4_CV_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(partial_results_dir + 'Experiment_4_test_scores.pickle', 'wb') as handle:\n",
    "            pickle.dump(Experiment_4_test_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print(\"\\t    + Elapsed: {} seconds\".format(np.round(time.perf_counter()-it_time_init), 2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export LaTeX tables/figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(partial_results_dir + '/Experiment_4_CV_scores.pickle', 'rb') as handle:\n",
    "        Experiment_4_CV_scores = pickle.load(handle)\n",
    "except:\n",
    "    Experiment_4_CV_scores = {}\n",
    "try:\n",
    "    with open(partial_results_dir + '/Experiment_4_test_scores.pickle', 'rb') as handle:\n",
    "        Experiment_4_test_scores = pickle.load(handle)\n",
    "except:\n",
    "    Experiment_4_test_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LightGBM': {'LPMC': {'Accuracy': 74.76443768996961,\n",
       "   'F1': 55.77533290152894,\n",
       "   'Recall': 55.86976689126527,\n",
       "   'GMPCA': 52.00953889879196,\n",
       "   'Estimation time': 5.394302400000015,\n",
       "   'Market_shares': array([17.001,  2.857, 36.225, 43.917]),\n",
       "   'WTP_history': None}},\n",
       " 'NN': {'LPMC': {'Accuracy': 74.22492401215806,\n",
       "   'F1': 55.252585435855494,\n",
       "   'Recall': 55.510437716485306,\n",
       "   'GMPCA': 51.34357600821821,\n",
       "   'Estimation time': 11.689457000000175,\n",
       "   'Market_shares': array([16.941,  2.9  , 36.089, 44.069]),\n",
       "   'WTP_history': None}},\n",
       " 'DNN': {'LPMC': {'Accuracy': 74.36170212765958,\n",
       "   'F1': 55.48164394231152,\n",
       "   'Recall': 55.92791501690747,\n",
       "   'GMPCA': 50.99265789019044,\n",
       "   'Estimation time': 4.8106472999998005,\n",
       "   'Market_shares': array([17.711,  2.784, 35.031, 44.474], dtype=float32),\n",
       "   'WTP_history': None}},\n",
       " 0: {'RUMBoost': {'SwissMetro': {'Accuracy': 67.99116997792495,\n",
       "    'F1': 49.43119812699326,\n",
       "    'Recall': 49.125855481671614,\n",
       "    'GMPCA': 46.97805026510724,\n",
       "    'Estimation time': 0.27646520000416785}}},\n",
       " 1: {'RUMBoost': {'SwissMetro': {'Accuracy': 67.40250183958794,\n",
       "    'F1': 47.9488098841595,\n",
       "    'Recall': 47.75448496707105,\n",
       "    'GMPCA': 48.35671446507372,\n",
       "    'Estimation time': 0.3832989999791607}}},\n",
       " 2: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.46946284032377,\n",
       "    'F1': 51.00166719955732,\n",
       "    'Recall': 50.01599273681857,\n",
       "    'GMPCA': 48.57105193526701,\n",
       "    'Estimation time': 0.3260682000545785}}},\n",
       " 3: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.94775570272259,\n",
       "    'F1': 51.4683648132314,\n",
       "    'Recall': 50.72675564982872,\n",
       "    'GMPCA': 47.97641329047822,\n",
       "    'Estimation time': 0.46650920005049556}}},\n",
       " 4: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.3355408388521,\n",
       "    'F1': 48.82457083949621,\n",
       "    'Recall': 48.23279214296387,\n",
       "    'GMPCA': 47.0992983271564,\n",
       "    'Estimation time': 0.2740341000026092}}},\n",
       " 5: {'RUMBoost': {'SwissMetro': {'Accuracy': 65.37895511405445,\n",
       "    'F1': 48.26354671103741,\n",
       "    'Recall': 47.89504280524713,\n",
       "    'GMPCA': 45.968342693631485,\n",
       "    'Estimation time': 0.2843874000245705}}},\n",
       " 6: {'RUMBoost': {'SwissMetro': {'Accuracy': 67.62325239146432,\n",
       "    'F1': 50.119536903640785,\n",
       "    'Recall': 49.220083625646225,\n",
       "    'GMPCA': 47.7129307572272,\n",
       "    'Estimation time': 0.2971419000532478}}},\n",
       " 7: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.59308314937455,\n",
       "    'F1': 50.278436796520154,\n",
       "    'Recall': 49.74540290510787,\n",
       "    'GMPCA': 46.50494780955552,\n",
       "    'Estimation time': 0.25165520003065467}}},\n",
       " 8: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.74025018395879,\n",
       "    'F1': 51.040895789026344,\n",
       "    'Recall': 50.14967504324361,\n",
       "    'GMPCA': 46.64735247944042,\n",
       "    'Estimation time': 0.2913375999778509}}},\n",
       " 9: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.92420897718911,\n",
       "    'F1': 53.166422328030094,\n",
       "    'Recall': 51.786299205211925,\n",
       "    'GMPCA': 47.42200661506904,\n",
       "    'Estimation time': 0.30689820006955415}}},\n",
       " 10: {'RUMBoost': {'SwissMetro': {'Accuracy': 67.58646063281824,\n",
       "    'F1': 50.4809249714321,\n",
       "    'Recall': 49.55779786572585,\n",
       "    'GMPCA': 47.56376916053807,\n",
       "    'Estimation time': 0.2541743000037968}}},\n",
       " 11: {'RUMBoost': {'SwissMetro': {'Accuracy': 65.67328918322296,\n",
       "    'F1': 49.79287432904272,\n",
       "    'Recall': 49.01426772674628,\n",
       "    'GMPCA': 44.902416510967726,\n",
       "    'Estimation time': 0.5130410999991}}},\n",
       " 12: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.98454746136865,\n",
       "    'F1': 55.26169293591939,\n",
       "    'Recall': 53.10976389144672,\n",
       "    'GMPCA': 49.35646394793323,\n",
       "    'Estimation time': 0.5400944000575691}}},\n",
       " 13: {'RUMBoost': {'SwissMetro': {'Accuracy': 67.80721118469462,\n",
       "    'F1': 52.12581585172605,\n",
       "    'Recall': 50.412169334303634,\n",
       "    'GMPCA': 48.41483138445714,\n",
       "    'Estimation time': 0.24655849998816848}}},\n",
       " 14: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.22516556291392,\n",
       "    'F1': 48.704681475322076,\n",
       "    'Recall': 48.66582807967148,\n",
       "    'GMPCA': 46.92917948227597,\n",
       "    'Estimation time': 0.3984203999862075}}},\n",
       " 15: {'RUMBoost': {'SwissMetro': {'Accuracy': 65.23178807947019,\n",
       "    'F1': 48.84227120905755,\n",
       "    'Recall': 47.9202569622732,\n",
       "    'GMPCA': 46.73314154661656,\n",
       "    'Estimation time': 0.2862125999527052}}},\n",
       " 16: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.21192052980133,\n",
       "    'F1': 51.7364556799452,\n",
       "    'Recall': 50.40146327255507,\n",
       "    'GMPCA': 48.47083804609843,\n",
       "    'Estimation time': 0.30900759994983673}}},\n",
       " 17: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.2487122884474,\n",
       "    'F1': 49.71002569519232,\n",
       "    'Recall': 49.48335918427232,\n",
       "    'GMPCA': 48.21782295763449,\n",
       "    'Estimation time': 0.41641920001711696}}},\n",
       " 18: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.35908756438558,\n",
       "    'F1': 48.62736545835373,\n",
       "    'Recall': 48.6518052156026,\n",
       "    'GMPCA': 49.08874201955884,\n",
       "    'Estimation time': 0.24330420000478625}}},\n",
       " 19: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.81383370125093,\n",
       "    'F1': 48.60850369689084,\n",
       "    'Recall': 48.43981321469472,\n",
       "    'GMPCA': 47.56692649451897,\n",
       "    'Estimation time': 0.26815830008126795}}},\n",
       " 20: {'LightGBM': {'SwissMetro': {'Accuracy': 73.16592811422944,\n",
       "    'F1': 65.7131667108363,\n",
       "    'Recall': 62.7998811331454,\n",
       "    'GMPCA': 54.555755184331076,\n",
       "    'Estimation time': 1.6963385999843013}},\n",
       "  'NN': {'SwissMetro': {'Accuracy': 70.95027080256031,\n",
       "    'F1': 63.15082089032189,\n",
       "    'Recall': 60.94846021496389,\n",
       "    'GMPCA': 52.16853712917806,\n",
       "    'Estimation time': 17.84111780000967}},\n",
       "  'DNN': {'SwissMetro': {'Accuracy': 71.49187592319055,\n",
       "    'F1': 62.04879012555584,\n",
       "    'Recall': 59.372529879346835,\n",
       "    'GMPCA': 52.73566896190399,\n",
       "    'Estimation time': 2.0502012000069954}}},\n",
       " 21: {'LightGBM': {'SwissMetro': {'Accuracy': 74.2983751846381,\n",
       "    'F1': 67.757354254049,\n",
       "    'Recall': 64.56410671320953,\n",
       "    'GMPCA': 55.5355597763322,\n",
       "    'Estimation time': 1.5525163999991491}},\n",
       "  'NN': {'SwissMetro': {'Accuracy': 70.35942885278187,\n",
       "    'F1': 62.444734455495684,\n",
       "    'Recall': 60.195420913998674,\n",
       "    'GMPCA': 52.086420005249366,\n",
       "    'Estimation time': 15.193820400018012}},\n",
       "  'DNN': {'SwissMetro': {'Accuracy': 70.40866568193009,\n",
       "    'F1': 60.847897238128034,\n",
       "    'Recall': 57.825273920752764,\n",
       "    'GMPCA': 52.294420093904556,\n",
       "    'Estimation time': 1.8783534000103828}}},\n",
       " 22: {'LightGBM': {'SwissMetro': {'Accuracy': 73.60905957656327,\n",
       "    'F1': 66.61148512445277,\n",
       "    'Recall': 63.60215481677501,\n",
       "    'GMPCA': 54.722335341229346,\n",
       "    'Estimation time': 1.4047489000076894}},\n",
       "  'NN': {'SwissMetro': {'Accuracy': 70.26095519448548,\n",
       "    'F1': 63.88078138399855,\n",
       "    'Recall': 62.229498676392716,\n",
       "    'GMPCA': 50.70910748495183,\n",
       "    'Estimation time': 8.364559200010262}},\n",
       "  'DNN': {'SwissMetro': {'Accuracy': 70.16248153618906,\n",
       "    'F1': 62.303466893444046,\n",
       "    'Recall': 60.324184906672166,\n",
       "    'GMPCA': 51.52919325766327,\n",
       "    'Estimation time': 2.3430148000188638}}},\n",
       " 23: {'LightGBM': {'SwissMetro': {'Accuracy': 73.51058591826687,\n",
       "    'F1': 66.29988738813691,\n",
       "    'Recall': 63.42929897279075,\n",
       "    'GMPCA': 54.779771767187334,\n",
       "    'Estimation time': 1.498622000013711}},\n",
       "  'NN': {'SwissMetro': {'Accuracy': 71.49187592319055,\n",
       "    'F1': 64.79981452836694,\n",
       "    'Recall': 63.06304920535578,\n",
       "    'GMPCA': 51.17614060793853,\n",
       "    'Estimation time': 12.842306500009727}},\n",
       "  'DNN': {'SwissMetro': {'Accuracy': 71.44263909404235,\n",
       "    'F1': 63.56009744959658,\n",
       "    'Recall': 61.03032243266796,\n",
       "    'GMPCA': 51.643110181787755,\n",
       "    'Estimation time': 3.4908833000226878}}},\n",
       " 24: {'LightGBM': {'SwissMetro': {'Accuracy': 73.31363860167404,\n",
       "    'F1': 67.0260380813136,\n",
       "    'Recall': 64.198688453796,\n",
       "    'GMPCA': 54.94875697563526,\n",
       "    'Estimation time': 2.234630399994785}},\n",
       "  'NN': {'SwissMetro': {'Accuracy': 70.7533234859675,\n",
       "    'F1': 62.965110048033345,\n",
       "    'Recall': 60.85168482499716,\n",
       "    'GMPCA': 51.523359909322075,\n",
       "    'Estimation time': 7.243247999984305}},\n",
       "  'DNN': {'SwissMetro': {'Accuracy': 69.42392909896603,\n",
       "    'F1': 59.30393249859717,\n",
       "    'Recall': 56.24924407403377,\n",
       "    'GMPCA': 50.860240681885614,\n",
       "    'Estimation time': 1.9410093999758828}}},\n",
       " 'ResLogit': {'LPMC': {'Accuracy': 73.25227963525836,\n",
       "   'F1': 54.46323352028959,\n",
       "   'Recall': 54.77340009557792,\n",
       "   'GMPCA': 50.40044120315231,\n",
       "   'Estimation time': 108.00776160007808}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment_4_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain accuracy tables\n",
    "Experiment_4_CV_table, Experiment_4_test_table, Experiment_4_time_table = construct_experiment_4_accuracy_table(Experiment_4_CV_scores, Experiment_4_test_scores)\n",
    "\n",
    "# Obtain market shares table over the test set\n",
    "#Experiment_4_MS_table = construct_experiment_4_market_shares_table(Experiment_4_test_scores, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ResLogit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPMC</th>\n",
       "      <td>73.64</td>\n",
       "      <td>50.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ResLogit       \n",
       "     Accuracy  GMPCA\n",
       "LPMC    73.64  50.99"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment_4_CV_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ResLogit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPMC</th>\n",
       "      <td>73.25</td>\n",
       "      <td>50.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ResLogit      \n",
       "     Accuracy GMPCA\n",
       "LPMC    73.25  50.4"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment_4_test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResLogit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPMC</th>\n",
       "      <td>95.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ResLogit\n",
       "LPMC    95.72"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment_4_time_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(partial_results_dir + '/Experiment_4_CV_scores_all.pickle', 'rb') as handle:\n",
    "        Experiment_4_CV_scores = pickle.load(handle)\n",
    "except:\n",
    "    Experiment_4_CV_scores = {}\n",
    "try:\n",
    "    with open(partial_results_dir + '/Experiment_4_test_scores_all.pickle', 'rb') as handle:\n",
    "        Experiment_4_test_scores = pickle.load(handle)\n",
    "except:\n",
    "    Experiment_4_test_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LightGBM': {'LPMC': {'Accuracy': 74.76443768996961,\n",
       "   'F1': 55.77533290152894,\n",
       "   'Recall': 55.86976689126527,\n",
       "   'GMPCA': 52.00953889879196,\n",
       "   'Estimation time': 5.394302400000015,\n",
       "   'Market_shares': array([17.001,  2.857, 36.225, 43.917]),\n",
       "   'WTP_history': None}},\n",
       " 'NN': {'LPMC': {'Accuracy': 74.22492401215806,\n",
       "   'F1': 55.252585435855494,\n",
       "   'Recall': 55.510437716485306,\n",
       "   'GMPCA': 51.34357600821821,\n",
       "   'Estimation time': 11.689457000000175,\n",
       "   'Market_shares': array([16.941,  2.9  , 36.089, 44.069]),\n",
       "   'WTP_history': None}},\n",
       " 'DNN': {'LPMC': {'Accuracy': 74.36170212765958,\n",
       "   'F1': 55.48164394231152,\n",
       "   'Recall': 55.92791501690747,\n",
       "   'GMPCA': 50.99265789019044,\n",
       "   'Estimation time': 4.8106472999998005,\n",
       "   'Market_shares': array([17.711,  2.784, 35.031, 44.474], dtype=float32),\n",
       "   'WTP_history': None}},\n",
       " 0: {'RUMBoost': {'SwissMetro': {'Accuracy': 67.99116997792495,\n",
       "    'F1': 49.43119812699326,\n",
       "    'Recall': 49.125855481671614,\n",
       "    'GMPCA': 46.97805026510724,\n",
       "    'Estimation time': 0.27646520000416785}}},\n",
       " 1: {'RUMBoost': {'SwissMetro': {'Accuracy': 67.40250183958794,\n",
       "    'F1': 47.9488098841595,\n",
       "    'Recall': 47.75448496707105,\n",
       "    'GMPCA': 48.35671446507372,\n",
       "    'Estimation time': 0.3832989999791607}}},\n",
       " 2: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.46946284032377,\n",
       "    'F1': 51.00166719955732,\n",
       "    'Recall': 50.01599273681857,\n",
       "    'GMPCA': 48.57105193526701,\n",
       "    'Estimation time': 0.3260682000545785}}},\n",
       " 3: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.94775570272259,\n",
       "    'F1': 51.4683648132314,\n",
       "    'Recall': 50.72675564982872,\n",
       "    'GMPCA': 47.97641329047822,\n",
       "    'Estimation time': 0.46650920005049556}}},\n",
       " 4: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.3355408388521,\n",
       "    'F1': 48.82457083949621,\n",
       "    'Recall': 48.23279214296387,\n",
       "    'GMPCA': 47.0992983271564,\n",
       "    'Estimation time': 0.2740341000026092}}},\n",
       " 5: {'RUMBoost': {'SwissMetro': {'Accuracy': 65.37895511405445,\n",
       "    'F1': 48.26354671103741,\n",
       "    'Recall': 47.89504280524713,\n",
       "    'GMPCA': 45.968342693631485,\n",
       "    'Estimation time': 0.2843874000245705}}},\n",
       " 6: {'RUMBoost': {'SwissMetro': {'Accuracy': 67.62325239146432,\n",
       "    'F1': 50.119536903640785,\n",
       "    'Recall': 49.220083625646225,\n",
       "    'GMPCA': 47.7129307572272,\n",
       "    'Estimation time': 0.2971419000532478}}},\n",
       " 7: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.59308314937455,\n",
       "    'F1': 50.278436796520154,\n",
       "    'Recall': 49.74540290510787,\n",
       "    'GMPCA': 46.50494780955552,\n",
       "    'Estimation time': 0.25165520003065467}}},\n",
       " 8: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.74025018395879,\n",
       "    'F1': 51.040895789026344,\n",
       "    'Recall': 50.14967504324361,\n",
       "    'GMPCA': 46.64735247944042,\n",
       "    'Estimation time': 0.2913375999778509}}},\n",
       " 9: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.92420897718911,\n",
       "    'F1': 53.166422328030094,\n",
       "    'Recall': 51.786299205211925,\n",
       "    'GMPCA': 47.42200661506904,\n",
       "    'Estimation time': 0.30689820006955415}}},\n",
       " 10: {'RUMBoost': {'SwissMetro': {'Accuracy': 67.58646063281824,\n",
       "    'F1': 50.4809249714321,\n",
       "    'Recall': 49.55779786572585,\n",
       "    'GMPCA': 47.56376916053807,\n",
       "    'Estimation time': 0.2541743000037968}}},\n",
       " 11: {'RUMBoost': {'SwissMetro': {'Accuracy': 65.67328918322296,\n",
       "    'F1': 49.79287432904272,\n",
       "    'Recall': 49.01426772674628,\n",
       "    'GMPCA': 44.902416510967726,\n",
       "    'Estimation time': 0.5130410999991}}},\n",
       " 12: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.98454746136865,\n",
       "    'F1': 55.26169293591939,\n",
       "    'Recall': 53.10976389144672,\n",
       "    'GMPCA': 49.35646394793323,\n",
       "    'Estimation time': 0.5400944000575691}}},\n",
       " 13: {'RUMBoost': {'SwissMetro': {'Accuracy': 67.80721118469462,\n",
       "    'F1': 52.12581585172605,\n",
       "    'Recall': 50.412169334303634,\n",
       "    'GMPCA': 48.41483138445714,\n",
       "    'Estimation time': 0.24655849998816848}}},\n",
       " 14: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.22516556291392,\n",
       "    'F1': 48.704681475322076,\n",
       "    'Recall': 48.66582807967148,\n",
       "    'GMPCA': 46.92917948227597,\n",
       "    'Estimation time': 0.3984203999862075}}},\n",
       " 15: {'RUMBoost': {'SwissMetro': {'Accuracy': 65.23178807947019,\n",
       "    'F1': 48.84227120905755,\n",
       "    'Recall': 47.9202569622732,\n",
       "    'GMPCA': 46.73314154661656,\n",
       "    'Estimation time': 0.2862125999527052}}},\n",
       " 16: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.21192052980133,\n",
       "    'F1': 51.7364556799452,\n",
       "    'Recall': 50.40146327255507,\n",
       "    'GMPCA': 48.47083804609843,\n",
       "    'Estimation time': 0.30900759994983673}}},\n",
       " 17: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.2487122884474,\n",
       "    'F1': 49.71002569519232,\n",
       "    'Recall': 49.48335918427232,\n",
       "    'GMPCA': 48.21782295763449,\n",
       "    'Estimation time': 0.41641920001711696}}},\n",
       " 18: {'RUMBoost': {'SwissMetro': {'Accuracy': 68.35908756438558,\n",
       "    'F1': 48.62736545835373,\n",
       "    'Recall': 48.6518052156026,\n",
       "    'GMPCA': 49.08874201955884,\n",
       "    'Estimation time': 0.24330420000478625}}},\n",
       " 19: {'RUMBoost': {'SwissMetro': {'Accuracy': 66.81383370125093,\n",
       "    'F1': 48.60850369689084,\n",
       "    'Recall': 48.43981321469472,\n",
       "    'GMPCA': 47.56692649451897,\n",
       "    'Estimation time': 0.26815830008126795}}},\n",
       " 20: {'LightGBM': {'SwissMetro': {'Accuracy': 73.16592811422944,\n",
       "    'F1': 65.7131667108363,\n",
       "    'Recall': 62.7998811331454,\n",
       "    'GMPCA': 54.555755184331076,\n",
       "    'Estimation time': 1.6963385999843013}},\n",
       "  'NN': {'SwissMetro': {'Accuracy': 70.95027080256031,\n",
       "    'F1': 63.15082089032189,\n",
       "    'Recall': 60.94846021496389,\n",
       "    'GMPCA': 52.16853712917806,\n",
       "    'Estimation time': 17.84111780000967}},\n",
       "  'DNN': {'SwissMetro': {'Accuracy': 71.49187592319055,\n",
       "    'F1': 62.04879012555584,\n",
       "    'Recall': 59.372529879346835,\n",
       "    'GMPCA': 52.73566896190399,\n",
       "    'Estimation time': 2.0502012000069954}}},\n",
       " 21: {'LightGBM': {'SwissMetro': {'Accuracy': 74.2983751846381,\n",
       "    'F1': 67.757354254049,\n",
       "    'Recall': 64.56410671320953,\n",
       "    'GMPCA': 55.5355597763322,\n",
       "    'Estimation time': 1.5525163999991491}},\n",
       "  'NN': {'SwissMetro': {'Accuracy': 70.35942885278187,\n",
       "    'F1': 62.444734455495684,\n",
       "    'Recall': 60.195420913998674,\n",
       "    'GMPCA': 52.086420005249366,\n",
       "    'Estimation time': 15.193820400018012}},\n",
       "  'DNN': {'SwissMetro': {'Accuracy': 70.40866568193009,\n",
       "    'F1': 60.847897238128034,\n",
       "    'Recall': 57.825273920752764,\n",
       "    'GMPCA': 52.294420093904556,\n",
       "    'Estimation time': 1.8783534000103828}}},\n",
       " 22: {'LightGBM': {'SwissMetro': {'Accuracy': 73.60905957656327,\n",
       "    'F1': 66.61148512445277,\n",
       "    'Recall': 63.60215481677501,\n",
       "    'GMPCA': 54.722335341229346,\n",
       "    'Estimation time': 1.4047489000076894}},\n",
       "  'NN': {'SwissMetro': {'Accuracy': 70.26095519448548,\n",
       "    'F1': 63.88078138399855,\n",
       "    'Recall': 62.229498676392716,\n",
       "    'GMPCA': 50.70910748495183,\n",
       "    'Estimation time': 8.364559200010262}},\n",
       "  'DNN': {'SwissMetro': {'Accuracy': 70.16248153618906,\n",
       "    'F1': 62.303466893444046,\n",
       "    'Recall': 60.324184906672166,\n",
       "    'GMPCA': 51.52919325766327,\n",
       "    'Estimation time': 2.3430148000188638}}},\n",
       " 23: {'LightGBM': {'SwissMetro': {'Accuracy': 73.51058591826687,\n",
       "    'F1': 66.29988738813691,\n",
       "    'Recall': 63.42929897279075,\n",
       "    'GMPCA': 54.779771767187334,\n",
       "    'Estimation time': 1.498622000013711}},\n",
       "  'NN': {'SwissMetro': {'Accuracy': 71.49187592319055,\n",
       "    'F1': 64.79981452836694,\n",
       "    'Recall': 63.06304920535578,\n",
       "    'GMPCA': 51.17614060793853,\n",
       "    'Estimation time': 12.842306500009727}},\n",
       "  'DNN': {'SwissMetro': {'Accuracy': 71.44263909404235,\n",
       "    'F1': 63.56009744959658,\n",
       "    'Recall': 61.03032243266796,\n",
       "    'GMPCA': 51.643110181787755,\n",
       "    'Estimation time': 3.4908833000226878}}},\n",
       " 24: {'LightGBM': {'SwissMetro': {'Accuracy': 73.31363860167404,\n",
       "    'F1': 67.0260380813136,\n",
       "    'Recall': 64.198688453796,\n",
       "    'GMPCA': 54.94875697563526,\n",
       "    'Estimation time': 2.234630399994785}},\n",
       "  'NN': {'SwissMetro': {'Accuracy': 70.7533234859675,\n",
       "    'F1': 62.965110048033345,\n",
       "    'Recall': 60.85168482499716,\n",
       "    'GMPCA': 51.523359909322075,\n",
       "    'Estimation time': 7.243247999984305}},\n",
       "  'DNN': {'SwissMetro': {'Accuracy': 69.42392909896603,\n",
       "    'F1': 59.30393249859717,\n",
       "    'Recall': 56.24924407403377,\n",
       "    'GMPCA': 50.860240681885614,\n",
       "    'Estimation time': 1.9410093999758828}}},\n",
       " 'ResLogit': {'LPMC': {'Accuracy': 73.25227963525836,\n",
       "   'F1': 54.46323352028959,\n",
       "   'Recall': 54.77340009557792,\n",
       "   'GMPCA': 50.40044120315231,\n",
       "   'Estimation time': 108.00776160007808}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Experiment_4_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain accuracy tables\n",
    "Experiment_4_CV_table, Experiment_4_test_table, Experiment_4_time_table = construct_experiment_4_accuracy_table(Experiment_4_CV_scores, Experiment_4_test_scores)\n",
    "\n",
    "# Obtain market shares table over the test set\n",
    "#Experiment_4_MS_table = construct_experiment_4_market_shares_table(Experiment_4_test_scores, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ResLogit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPMC</th>\n",
       "      <td>73.64</td>\n",
       "      <td>50.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ResLogit       \n",
       "     Accuracy  GMPCA\n",
       "LPMC    73.64  50.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Experiment_4_CV_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ResLogit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>GMPCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPMC</th>\n",
       "      <td>73.25</td>\n",
       "      <td>50.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ResLogit      \n",
       "     Accuracy GMPCA\n",
       "LPMC    73.25  50.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Experiment_4_test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResLogit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPMC</th>\n",
       "      <td>95.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ResLogit\n",
       "LPMC    95.72"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Experiment_4_time_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('JAT2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77c86185ec3449d48075597ae5d9be3b197927273fdfcf86afca3b724749e4b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
